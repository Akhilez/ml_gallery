{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from app.rl.tictactoe.t3_test import T3Model, convert_inputs\n",
    "from gym_tic_tac_toe.envs.tic_tac_toe_env import TicTacToeEnv, Pix\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = T3Model(embed_dim=16, attentions_depth=4).double().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def play(player_1, player_2, render=False):\n",
    "    env = TicTacToeEnv()\n",
    "    env.reset()\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    info = {}\n",
    "    is_done = False\n",
    "    while not is_done:\n",
    "        player = player_1 if env.player == Pix.X else player_2\n",
    "        action = player(env)\n",
    "        state, reward, is_done, info = env.step(action)\n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "    won = info.get('won')\n",
    "    if won:\n",
    "        return 1 if won == Pix.X.string else 2\n",
    "    return 0\n",
    "\n",
    "\n",
    "def random_player(env, legal_actions=None):\n",
    "    legal_actions = legal_actions if legal_actions is not None else env.get_legal_actions()\n",
    "    random_idx = int(torch.randint(low=0, high=len(legal_actions), size=(1,))[0])\n",
    "    return legal_actions[random_idx]\n",
    "\n",
    "\n",
    "class AIPlayer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, env, legal_actions=None):\n",
    "        legal_actions = legal_actions if legal_actions is not None else env.get_legal_actions()\n",
    "        xs = [convert_inputs(env.state, env.player)]\n",
    "        xs = torch.stack(xs).long().to(device)\n",
    "        was_train = self.model.training\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            yh = self.model(xs)  # yh shape: (batch, 9)\n",
    "\n",
    "        if was_train:\n",
    "            self.model.train()\n",
    "\n",
    "        action_idx = int(yh[0, legal_actions].argmax())\n",
    "\n",
    "        return legal_actions[action_idx]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49: 30.21360529938356, plays: (1, 87, 12)\n",
      "99: 28.168538563179666, plays: (3, 91, 6)\n",
      "149: 25.788826016648056, plays: (3, 80, 17)\n",
      "199: 16.971596597940437, plays: (1, 64, 35)\n",
      "249: 34.42780111884201, plays: (14, 73, 13)\n",
      "299: 18.69235574061382, plays: (0, 60, 40)\n",
      "349: 19.77148711535501, plays: (0, 63, 37)\n",
      "399: 19.275144098447925, plays: (35, 55, 10)\n",
      "449: 19.70377338065305, plays: (4, 57, 39)\n",
      "499: 18.47877040648549, plays: (15, 77, 8)\n",
      "549: 16.768630590390885, plays: (5, 83, 12)\n",
      "599: 14.559066044208128, plays: (2, 69, 29)\n",
      "649: 14.661679889235796, plays: (0, 68, 32)\n",
      "699: 21.682417929052672, plays: (0, 52, 48)\n",
      "749: 20.951792181445775, plays: (0, 51, 49)\n",
      "799: 19.968842781816715, plays: (1, 52, 47)\n",
      "849: 19.333843896963153, plays: (2, 61, 37)\n",
      "899: 23.189217719264107, plays: (0, 62, 38)\n",
      "949: 29.768398982196064, plays: (0, 81, 19)\n",
      "999: 21.31159065967773, plays: (0, 77, 23)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_credits(t, gamma):\n",
    "    credits = []\n",
    "    prev_credit = 1\n",
    "    for i in range(t):\n",
    "        credits.append(prev_credit)\n",
    "        prev_credit *= gamma\n",
    "    return torch.tensor(list(reversed(credits))).double().to(device)\n",
    "\n",
    "\n",
    "def get_returns(stats, gamma):\n",
    "    total_t = len(stats)\n",
    "    returns = []\n",
    "    prev_return = 0\n",
    "    for t in range(total_t):\n",
    "        prev_return = stats[total_t - t -1][1] + (gamma * prev_return)\n",
    "        returns.append(prev_return)\n",
    "    return torch.tensor(list(reversed(returns))).double().to(device)\n",
    "\n",
    "\n",
    "def get_loss(stats):\n",
    "    loss = 0\n",
    "    for i_env in range(len(stats)):\n",
    "        returns = get_returns(stats[i_env], gamma=0.75)\n",
    "\n",
    "        probs = torch.stack([stat[0] for stat in stats[i_env]])\n",
    "        probs = torch.log(probs)\n",
    "\n",
    "        credits = get_credits(len(stats[i_env]), gamma=0.75)\n",
    "\n",
    "        loss += torch.sum(probs * credits * returns) / len(stats[i_env])\n",
    "    return -1 * loss / len(stats)\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 10000\n",
    "\n",
    "    model.train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    envs = [TicTacToeEnv() for _ in range(batch_size)]\n",
    "    losses = []\n",
    "    opponent = AIPlayer(copy.deepcopy(model))\n",
    "    prev_models = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Before game starts\n",
    "\n",
    "        me_idx_bool = torch.arange(batch_size) > (batch_size - 1) / 2\n",
    "        stats = [[] for _ in range(batch_size)]\n",
    "        is_dones = [False for _ in range(batch_size)]\n",
    "        _ = [env.reset() for env in envs]\n",
    "        ai_pieces = [Pix.X if me_idx_bool[i] else Pix.O for i in range(batch_size)]\n",
    "\n",
    "        # Monte Carlo loop\n",
    "        for t in range(15):\n",
    "            legal_actions = [env.get_legal_actions() for env in envs]\n",
    "\n",
    "            xs = [convert_inputs(envs[i].state, envs[i].player) for i in range(batch_size)]\n",
    "            xs = torch.stack(xs).long().to(device)\n",
    "\n",
    "            yh = model(xs)  # yh shape: (batch, 9)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                if not is_dones[i]:\n",
    "\n",
    "                    # Is current player AI or other?\n",
    "                    if envs[i].player == ai_pieces[i]:\n",
    "                        legal_probs = F.softmax(yh[i, legal_actions[i]], 0)\n",
    "                        action_idx = int(torch.multinomial(legal_probs, 1).squeeze())\n",
    "\n",
    "                        state, reward, is_done, info = envs[i].step(legal_actions[i][action_idx])\n",
    "\n",
    "                        prob = legal_probs[action_idx]\n",
    "                        stats[i].append([prob, reward])\n",
    "                    else:\n",
    "                        action = opponent(envs[i], legal_actions[i])\n",
    "                        _, _, is_done, _ = envs[i].step(action)\n",
    "\n",
    "                    is_dones[i] = is_done\n",
    "\n",
    "            if all(is_dones):\n",
    "                break\n",
    "\n",
    "        loss = get_loss(stats)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            plays = [play(AIPlayer(model), opponent) for _ in range(50)]\n",
    "            plays = plays + [play(opponent, AIPlayer(model)) for _ in range(50)]\n",
    "            winners = torch.tensor(plays).float()\n",
    "\n",
    "            draws = len(torch.nonzero(winners == 0))\n",
    "            wins = len(torch.nonzero(winners == 1))\n",
    "            loses = len(torch.nonzero(winners == 2))\n",
    "\n",
    "            print(f'{epoch}: {np.mean(losses)}, plays: {draws, wins, loses}')\n",
    "\n",
    "            # if (epoch + 1) % 1000 == 0:\n",
    "            # plt.plot(losses)\n",
    "            # plt.show()\n",
    "\n",
    "            losses = []\n",
    "            prev_models = prev_models[-10:]\n",
    "            prev_models.append(copy.deepcopy(model))\n",
    "            opponent.model = prev_models[np.random.choice(len(prev_models), 1)[0]]\n",
    "\n",
    "\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            plays = [play(AIPlayer(model), random_player) for _ in range(100)]\n",
    "            winners = torch.tensor(plays).float()\n",
    "\n",
    "            draws = len(torch.nonzero(winners == 0))\n",
    "            wins = len(torch.nonzero(winners == 1))\n",
    "            loses = len(torch.nonzero(winners == 2))\n",
    "            print(f\"Against random guy: \", end='')\n",
    "            print(draws, wins, loses, end=', ')\n",
    "\n",
    "            plays = [play(random_player, AIPlayer(model)) for _ in range(100)]\n",
    "            winners = torch.tensor(plays).float()\n",
    "\n",
    "            draws = len(torch.nonzero(winners == 0))\n",
    "            wins = len(torch.nonzero(winners == 1))\n",
    "            loses = len(torch.nonzero(winners == 2))\n",
    "\n",
    "            print(draws, wins, loses)\n",
    "\n",
    "            play(random_player, AIPlayer(model), render=True)\n",
    "            play(AIPlayer(model), random_player, render=True)\n",
    "\n",
    "train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(14, 55, 31)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plays = [play(AIPlayer(model), random_player) for _ in range(100)]\n",
    "winners = torch.tensor(plays).float()\n",
    "\n",
    "draws = len(torch.nonzero(winners == 0))\n",
    "wins = len(torch.nonzero(winners == 1))\n",
    "loses = len(torch.nonzero(winners == 2))\n",
    "\n",
    "draws, wins, loses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(7, 57, 36)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plays = [play(random_player, AIPlayer(model)) for _ in range(100)]\n",
    "winners = torch.tensor(plays).float()\n",
    "\n",
    "draws = len(torch.nonzero(winners == 0))\n",
    "wins = len(torch.nonzero(winners == 1))\n",
    "loses = len(torch.nonzero(winners == 2))\n",
    "\n",
    "draws, wins, loses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "___\n",
      "___\n",
      "\n",
      "___\n",
      "__X\n",
      "___\n",
      "\n",
      "___\n",
      "__X\n",
      "O__\n",
      "\n",
      "___\n",
      "__X\n",
      "OX_\n",
      "\n",
      "___\n",
      "_OX\n",
      "OX_\n",
      "\n",
      "__X\n",
      "_OX\n",
      "OX_\n",
      "\n",
      "O_X\n",
      "_OX\n",
      "OX_\n",
      "\n",
      "O_X\n",
      "_OX\n",
      "OXX\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play(random_player, AIPlayer(model), render=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}