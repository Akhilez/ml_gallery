{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from app.rl.alpha_nine.a9 import A9Model, convert_inputs\n",
    "from gym_nine_mens_morris.envs.nine_mens_morris_env import NineMensMorrisEnv, Pix\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = A9Model(8, 4, 4, 4).double().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def subsample_legal_positions(probs, legal_pos):\n",
    "    \"\"\"\n",
    "    probs: tensor of shape (24)\n",
    "    legal_pos: list of tuples. Shape: (n, 3)\n",
    "    \"\"\"\n",
    "    flattened_idx = [np.ravel_multi_index(pos, (3, 2, 4)) for pos in legal_pos]\n",
    "    return probs[flattened_idx]\n",
    "\n",
    "\n",
    "def sample_action(legal_actions, pos1, pos2, move, kill, is_phase_1, argmax=False):\n",
    "    probs = []\n",
    "\n",
    "    legal_pos = list(set([action[0] for action in legal_actions]))  # [(3, 2, 4), (3, 2, 4), ... ]\n",
    "    pos_probs_ = pos1 if is_phase_1 else pos2\n",
    "    # subsample pos_probs with legal actions\n",
    "    pos_probs = subsample_legal_positions(pos_probs_, legal_pos)\n",
    "    pos_idx = int(pos_probs.argmax()) if argmax else int(torch.multinomial(pos_probs, 1).squeeze())  # 24\n",
    "    pos = legal_pos[pos_idx]  # (3, 2, 4)\n",
    "    probs.append(pos_probs[pos_idx])\n",
    "\n",
    "    # [0, 1, 2, 3]\n",
    "    legal_moves = list(\n",
    "        set([action[1] for action in legal_actions if tuple(action[0]) == tuple(pos) and action[1] is not None]))\n",
    "    if len(legal_moves) != 0:\n",
    "        move = move[legal_moves]\n",
    "        move_idx = int(move.argmax()) if argmax else int(torch.multinomial(move, 1).squeeze())  # 4\n",
    "        move_ = legal_moves[move_idx]  # 4\n",
    "        probs.append(move[move_idx])\n",
    "    else:\n",
    "        move_ = None\n",
    "\n",
    "    legal_kills = list(\n",
    "        set([tuple(action[2]) for action in legal_actions if tuple(action[0]) == tuple(pos) and action[2] is not None]))\n",
    "    if len(legal_kills) != 0:\n",
    "        kill = subsample_legal_positions(kill, legal_kills)\n",
    "        kill_idx = int(kill.argmax()) if argmax else int(torch.multinomial(kill, 1).squeeze())\n",
    "        kill_ = legal_kills[kill_idx]  # (3, 2, 4)\n",
    "        probs.append(kill[kill_idx])\n",
    "    else:\n",
    "        kill_ = None\n",
    "\n",
    "    return (pos, move_, kill_), torch.mean(torch.stack(probs))\n",
    "\n",
    "\n",
    "def reset_opponent_model(opponent, prev_models):\n",
    "    prev_models = prev_models[-20:]\n",
    "    prev_models.append(copy.deepcopy(model))\n",
    "    opponent.model = prev_models[np.random.choice(len(prev_models), 1)[0]]\n",
    "    opponent.model.eval()\n",
    "    return prev_models\n",
    "\n",
    "\n",
    "def play(player_1, player_2, render=False):\n",
    "    env = NineMensMorrisEnv()\n",
    "    env.reset()\n",
    "    if render:\n",
    "        env.render()\n",
    "\n",
    "    info = {}\n",
    "    is_done = False\n",
    "    while not is_done:\n",
    "        player = player_1 if env.player == Pix.W else player_2\n",
    "        state, reward, is_done, info = env.step(player(env))\n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "    winner = info.get('winner')\n",
    "    if winner:\n",
    "        return 1 if winner == Pix.W.string else 2\n",
    "    return 0\n",
    "\n",
    "\n",
    "def random_player(env, legal_actions=None):\n",
    "    legal_actions = legal_actions if legal_actions is not None else env.get_legal_actions()\n",
    "    if len(legal_actions) == 0:\n",
    "        env.swap_players()\n",
    "        return (0, 0, 0), None, None\n",
    "    random_idx = int(torch.randint(low=0, high=len(legal_actions), size=(1,))[0])\n",
    "    random_action = legal_actions[random_idx]\n",
    "    return random_action\n",
    "\n",
    "\n",
    "class AIPlayer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, env, legal_actions=None):\n",
    "        legal_actions = legal_actions if legal_actions is not None else env.get_legal_actions()\n",
    "        if len(legal_actions) == 0:\n",
    "            env.swap_players()\n",
    "            return (0, 0, 0), None, None\n",
    "\n",
    "        xs = create_state_batch([env])\n",
    "\n",
    "        was_train = self.model.training\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            yh_pos_1, yh_pos_2, yh_move, yh_kill = self.model(xs)  # yh shape: (batch, 9)\n",
    "\n",
    "        if was_train:\n",
    "            self.model.train()\n",
    "\n",
    "        action, _ = sample_action(legal_actions, yh_pos_1[0], yh_pos_2[0], yh_move[0], yh_kill[0],\n",
    "                                  env.is_phase_1(), argmax=False)\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "def randomize_ai_player(stats):\n",
    "    batch_size = len(stats)\n",
    "\n",
    "    # First half are False and second half are True\n",
    "    bools = torch.arange(batch_size) > (batch_size - 1) / 2\n",
    "\n",
    "    # Randomly shuffle equal number of Falses and Trues\n",
    "    bools = bools[torch.randperm(batch_size)]\n",
    "\n",
    "    # Set player's piece to these random values\n",
    "    for i in range(batch_size):\n",
    "        stats[i].player = Pix.W if bools[i] else Pix.B\n",
    "\n",
    "\n",
    "def create_state_batch(envs):\n",
    "    xs = [convert_inputs(env.board, env.player) for env in envs]\n",
    "    xs = torch.stack(xs).long().to(device)\n",
    "    return xs\n",
    "\n",
    "\n",
    "def is_all_done(stats):\n",
    "    for stat in stats:\n",
    "        if not stat.env.is_done:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_credits(t, gamma):\n",
    "    credits = []\n",
    "    prev_credit = 1\n",
    "    for i in range(t):\n",
    "        credits.append(prev_credit)\n",
    "        prev_credit *= gamma\n",
    "    return torch.tensor(list(reversed(credits))).double().to(device)\n",
    "\n",
    "\n",
    "def get_returns(rewards, gamma):\n",
    "    total_t = len(rewards)\n",
    "    returns = []\n",
    "    prev_return = 0\n",
    "    for t in range(total_t):\n",
    "        prev_return = rewards[total_t - t - 1] + (gamma * prev_return)\n",
    "        returns.append(prev_return)\n",
    "    return torch.tensor(list(reversed(returns))).double().to(device)\n",
    "\n",
    "\n",
    "def get_loss(stats):\n",
    "    loss = 0\n",
    "    for i_env in range(len(stats)):\n",
    "\n",
    "        returns = get_returns(stats[i_env].rewards, gamma=0.99)\n",
    "        probs = torch.log(torch.stack([prob for prob in stats[i_env].probs]))\n",
    "        credits = get_credits(len(stats[i_env].rewards), gamma=0.99)\n",
    "\n",
    "        loss += torch.mean(probs * credits * returns)\n",
    "    return -1 * loss / len(stats)\n",
    "\n",
    "\n",
    "class Stat:\n",
    "    def __init__(self):\n",
    "        self.player = Pix.W\n",
    "        self.env = NineMensMorrisEnv()\n",
    "        self.steps = []\n",
    "        self.has_won = None\n",
    "        self.probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "        self.env.reset()\n",
    "\n",
    "\n",
    "class EpisodicStat:\n",
    "    def __init__(self, batch_size):\n",
    "        self.loss = None\n",
    "        self.stats = [Stat() for _ in range(batch_size)]\n",
    "\n",
    "\n",
    "def plot_interval(stats, episode_number):\n",
    "    losses = [stat.loss for stat in stats]\n",
    "\n",
    "    print(f'{episode_number}: {np.mean(losses)}', end='\\t')\n",
    "\n",
    "    wins, loses, plays = 0, 0, 0\n",
    "    for stat_ep in stats:\n",
    "        for stat_t in stat_ep.stats:\n",
    "            plays += 1\n",
    "            if stat_t.has_won:\n",
    "                wins += 1\n",
    "            else:\n",
    "                loses += 1\n",
    "\n",
    "    print(f'W: {wins / plays * 100} L: {loses / plays * 100} P: {plays}')\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_time_step(stats, opponent):\n",
    "    xs = create_state_batch([stat.env for stat in stats])\n",
    "\n",
    "    yh = model(xs)\n",
    "    with torch.no_grad():\n",
    "        yh_op = opponent.model(xs)\n",
    "\n",
    "    for i in range(len(stats)):\n",
    "        if not stats[i].env.is_done:\n",
    "            env = stats[i].env\n",
    "\n",
    "            legal_actions = env.get_legal_actions()\n",
    "            if len(legal_actions) == 0:\n",
    "                env.swap_players()\n",
    "                continue\n",
    "\n",
    "            # Is current player AI or other?\n",
    "            if env.player == stats[i].player:\n",
    "                action, prob = sample_action(legal_actions, yh[0][i], yh[1][i], yh[2][i], yh[3][i], env.is_phase_1())\n",
    "                state, reward, is_done, info = env.step(action)\n",
    "\n",
    "                stats[i].probs.append(prob)\n",
    "                stats[i].rewards.append(reward)\n",
    "            else:\n",
    "                action, _ = sample_action(legal_actions, yh_op[0][i], yh_op[1][i], yh_op[2][i], yh_op[3][i],\n",
    "                                          env.is_phase_1())\n",
    "                _, _, is_done, info = env.step(action)\n",
    "\n",
    "            if is_done:\n",
    "                stats[i].has_won = stats[i].player.string == info.get('winner')\n",
    "\n",
    "\n",
    "def train():\n",
    "    batch_size = 16\n",
    "    episodes = 100\n",
    "    reset_length = 20\n",
    "    episodic_stats = []\n",
    "    prev_models = []\n",
    "\n",
    "    model.train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    opponent = AIPlayer(copy.deepcopy(model))\n",
    "    opponent.model.eval()\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        stat_ep = EpisodicStat(batch_size)\n",
    "\n",
    "        randomize_ai_player(stat_ep.stats)\n",
    "\n",
    "        # Monte Carlo loop\n",
    "        while not is_all_done(stat_ep.stats):\n",
    "            run_time_step(stat_ep.stats, opponent)\n",
    "\n",
    "        loss = get_loss(stat_ep.stats)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        stat_ep.loss = loss.item()\n",
    "        episodic_stats.append(stat_ep)\n",
    "\n",
    "        if (episode + 1) % reset_length == 0:\n",
    "            plot_interval(episodic_stats, episode)\n",
    "            episodic_stats = []\n",
    "            prev_models = reset_opponent_model(opponent, prev_models)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plays = [play(AIPlayer(model), random_player) for _ in range(100)]\n",
    "winners = torch.tensor(plays).float()\n",
    "\n",
    "draws = len(torch.nonzero(winners == 0))\n",
    "wins = len(torch.nonzero(winners == 1))\n",
    "loses = len(torch.nonzero(winners == 2))\n",
    "\n",
    "draws, wins, loses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plays = [play(random_player, AIPlayer(model)) for _ in range(100)]\n",
    "winners = torch.tensor(plays).float()\n",
    "\n",
    "draws = len(torch.nonzero(winners == 0))\n",
    "wins = len(torch.nonzero(winners == 1))\n",
    "loses = len(torch.nonzero(winners == 2))\n",
    "\n",
    "draws, wins, loses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "play(random_player, AIPlayer(model), render=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "play(random_player, random_player, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[0.99 ** i for i in range(100)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}