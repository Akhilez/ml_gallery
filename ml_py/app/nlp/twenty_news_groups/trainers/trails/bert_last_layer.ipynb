{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of bert_test1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcQjFWpExRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "779182b0-28da-40ae-f42c-e7cce47638ba"
      },
      "source": [
        "!pip install pytorch_pretrained_bert pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.30 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.17.30)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.30->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.30->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.30->boto3->pytorch_pretrained_bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03YcbT9HSJtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "9c992915-cfe5-4c0f-a7e0-103c8b9477d4"
      },
      "source": [
        "# Downlod the dataset\n",
        "\n",
        "! rm -rf data\n",
        "! rm *.csv*\n",
        "! wget https://storage.googleapis.com/akhilez/datasets/singularity_systems/test_bert.csv\n",
        "! wget https://storage.googleapis.com/akhilez/datasets/singularity_systems/train_bert.csv\n",
        "! mkdir -p data\n",
        "! mv *.csv data/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.csv*': No such file or directory\n",
            "--2020-08-01 03:28:34--  https://storage.googleapis.com/akhilez/datasets/singularity_systems/test_bert.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 172.217.204.128, 172.217.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16310138 (16M) [text/csv]\n",
            "Saving to: ‘test_bert.csv’\n",
            "\n",
            "test_bert.csv       100%[===================>]  15.55M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-08-01 03:28:34 (135 MB/s) - ‘test_bert.csv’ saved [16310138/16310138]\n",
            "\n",
            "--2020-08-01 03:28:35--  https://storage.googleapis.com/akhilez/datasets/singularity_systems/train_bert.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.13.128, 172.217.204.128, 172.217.203.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.13.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23291221 (22M) [text/csv]\n",
            "Saving to: ‘train_bert.csv’\n",
            "\n",
            "train_bert.csv      100%[===================>]  22.21M   116MB/s    in 0.2s    \n",
            "\n",
            "2020-08-01 03:28:35 (116 MB/s) - ‘train_bert.csv’ saved [23291221/23291221]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NetGg_y82BMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "import csv\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHlswuXv1PUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1e0204b-178f-4d2f-f87a-6e62233666c2"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALahN1BA0tFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchGenerator:\n",
        "\n",
        "    def __init__(self, data_path, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "        self.data_path = data_path\n",
        "        self.n_labels = 20\n",
        "\n",
        "    def get_batch_gen(self, repeat=True):\n",
        "        while True:\n",
        "            with open(self.data_path) as data_file:\n",
        "                reader = csv.reader(data_file)\n",
        "                batch = []\n",
        "                for row in reader:  # TODO: Can the next batch be fetched asynchronously? With asyncio?\n",
        "                    batch.append(row)\n",
        "                    if len(batch) >= self.batch_size:\n",
        "                        batch = self._split_batch(batch)\n",
        "                        yield batch\n",
        "                        batch = []\n",
        "                if 0 < len(batch) < self.batch_size:\n",
        "                    yield self._split_batch(batch)\n",
        "            if not repeat:\n",
        "                break\n",
        "\n",
        "    def _split_batch(self, batch):\n",
        "        batch = np.array(batch, dtype=int)\n",
        "        x = batch[:, :len(batch[0]) - self.n_labels]\n",
        "        y = batch[:, len(batch[0]) - self.n_labels:]\n",
        "        return x, y\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m53j4b9L1D95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertEmailClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertEmailClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.linear1 = nn.Linear(768, 500)\n",
        "        self.linear2 = nn.Linear(500, 20)\n",
        "\n",
        "    def forward(self, x, masks=None):\n",
        "        _, x = self.bert(x, attention_mask=masks, output_all_encoded_layers=False)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.dropout2(nn.functional.relu(self.linear1(x)))\n",
        "        x = nn.functional.softmax(self.linear2(x), dim=1)\n",
        "        return x\n",
        "\n",
        "bert_clf = BertEmailClassifier().to(device)\n",
        "optim = torch.optim.Adam(list(bert_clf.linear1.parameters()) + list(bert_clf.linear2.parameters()))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL7JJyMW1EMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = 10\n",
        "test_batch_size = 5\n",
        "train_size = 11083\n",
        "test_size = 7761\n",
        "train_steps = train_size / train_batch_size\n",
        "test_steps = test_size / test_batch_size\n",
        "\n",
        "train_gen = BatchGenerator(data_path='data/train_bert.csv', batch_size=train_batch_size).get_batch_gen()\n",
        "test_gen = BatchGenerator(data_path='data/test_bert.csv', batch_size=test_batch_size).get_batch_gen()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fysrAh7wuaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6d07fac-ae8b-405b-938e-d8cd73560d02"
      },
      "source": [
        "train_steps"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1108.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U4i18RiBCxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4c570bf7-b143-4ed9-8fb6-445343f23d61"
      },
      "source": [
        "print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
        "torch.cuda.empty_cache()\n",
        "print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "441.201664M\n",
            "441.201664M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAhQMNScdOFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Metrics:\n",
        "    def __init__(self):\n",
        "        self.losses = []\n",
        "        self.accuracies = []\n",
        "\n",
        "        self._epoch_loss = 0\n",
        "        self._epoch_accuracy = 0\n",
        "\n",
        "        self.n_batches = 0\n",
        "        self.n_epochs = 0\n",
        "\n",
        "    def record_batch(self, loss, accuracy):\n",
        "        self.n_batches += 1\n",
        "        self._epoch_loss += loss\n",
        "        self._epoch_accuracy += accuracy\n",
        "\n",
        "    def record_epoch(self):\n",
        "        self.losses.append(self._epoch_loss/self.n_batches)\n",
        "        self.accuracies.append(self._epoch_accuracy/self.n_batches)\n",
        "\n",
        "        self.n_epochs += 1\n",
        "        self._epoch_loss = 0\n",
        "        self._epoch_accuracy = 0\n",
        "        self.n_batches = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def find_accuracy(y_hat, y_real):\n",
        "        max_args_equals = torch.argmax(y_hat, dim=1) == torch.argmax(y_real, dim=1)\n",
        "        return sum([1 if value else 0 for value in max_args_equals]) / len(y_hat)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHUv4ggnco6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def record_test_metrics(metrics):\n",
        "    with torch.no_grad():\n",
        "        for batch_i in range(math.ceil(test_steps)):\n",
        "\n",
        "            x_batch, y_batch = next(test_gen)\n",
        "            x_batch = torch.tensor(x_batch).to(device)\n",
        "            y_batch = torch.tensor(y_batch, dtype=torch.float32).to(device)\n",
        "            x_batch_masks = torch.tensor([[float(i > 0) for i in ii] for ii in x_batch]).to(device)\n",
        "\n",
        "            y_hat = bert_clf(x_batch, x_batch_masks)\n",
        "\n",
        "            loss = nn.functional.binary_cross_entropy(y_hat, y_batch)\n",
        "\n",
        "            metrics.record_batch(loss.item(), Metrics.find_accuracy(y_hat, y_batch))\n",
        "\n",
        "            if batch_i % 200 == 0:\n",
        "                print(loss.item())\n",
        "\n",
        "        metrics.record_epoch()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Wj6-cD1EbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "39cb174c-f04b-4030-96f2-e23c7155d17b"
      },
      "source": [
        "def train(epochs, train_metrics, test_metrics):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for batch_i in range(math.ceil(train_steps)):\n",
        "\n",
        "            x_batch, y_batch = next(train_gen)\n",
        "            y_batch = torch.tensor(y_batch, dtype=torch.float32).to(device)\n",
        "            x_batch_masks = torch.tensor([[float(i > 0) for i in ii] for ii in x_batch]).to(device)\n",
        "            x_batch = torch.tensor(x_batch).to(device)\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "            y_hat = bert_clf(x_batch, x_batch_masks)\n",
        "\n",
        "            loss = nn.functional.binary_cross_entropy(y_hat, y_batch)\n",
        "\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            train_metrics.record_batch(loss.item(), Metrics.find_accuracy(y_hat, y_batch))\n",
        "\n",
        "            if batch_i % 200 == 0:\n",
        "                print(loss.item())\n",
        "\n",
        "        train_metrics.record_epoch()\n",
        "        record_test_metrics(test_metrics)\n",
        "\n",
        "        print(f'Epoch: {epoch}, train_loss={train_metrics.losses[-1]}, train_accuracy={train_metrics.accuracies[-1]}, val_loss={test_metrics.losses[-1]}, val_accuracy={test_metrics.accuracies[-1]}')\n",
        "\n",
        "train_metrics = Metrics()\n",
        "test_metrics = Metrics()\n",
        "\n",
        "train(5, train_metrics, test_metrics)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.202034130692482\n",
            "0.19044330716133118\n",
            "0.19049082696437836\n",
            "0.16164638102054596\n",
            "0.17933432757854462\n",
            "0.16792289912700653\n",
            "0.2199738323688507\n",
            "0.18984578549861908\n",
            "0.15281912684440613\n",
            "0.18067912757396698\n",
            "0.1672685593366623\n",
            "0.16764213144779205\n",
            "0.195363387465477\n",
            "0.20293845236301422\n",
            "Epoch: 0, train_loss=0.18593045756073015, train_accuracy=0.12669071235347126, val_loss=0.1828169930349683, val_accuracy=0.1448808757244033\n",
            "0.18299132585525513\n",
            "0.1499571055173874\n",
            "0.15501031279563904\n",
            "0.14058807492256165\n",
            "0.14288629591464996\n",
            "0.14687983691692352\n",
            "0.1924676150083542\n",
            "0.1758795529603958\n",
            "0.11508718132972717\n",
            "0.150018572807312\n",
            "0.14842583239078522\n",
            "0.17336471378803253\n",
            "0.15991012752056122\n",
            "0.16224698722362518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-72e7b7e1e666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-72e7b7e1e666>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, train_metrics, test_metrics)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mrecord_test_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch}, train_loss={train_metrics.losses[-1]}, train_accuracy={train_metrics.accuracies[-1]}, val_loss={test_metrics.losses[-1]}, val_accuracy={test_metrics.accuracies[-1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-6ac94d0288a2>\u001b[0m in \u001b[0;36mrecord_test_metrics\u001b[0;34m(metrics)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_i\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n46mNVMv_sXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_metrics.accuracies)\n",
        "plt.plot(test_metrics.accuracies)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['accuracy', 'val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8pAbU2gIUK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_metrics.losses)\n",
        "plt.plot(test_metrics.losses)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-UNGhiapRK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(bert_clf, 'bert_clf2.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSHdgt0_p_9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('bert_clf2.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySfoVlmo_Xrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}