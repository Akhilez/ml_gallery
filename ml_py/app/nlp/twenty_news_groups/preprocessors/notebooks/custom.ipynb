{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "test1.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I need tensorflow 2.3 version. Install it here and restart the runtime.\n",
    "!pip install tf-nightly > install.log\n",
    "# Make sure to restart runtime"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "! wget https://storage.googleapis.com/akhilez/datasets/singularity_systems/data.tgz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reload up the dataset\n",
    "! rm -rf data\n",
    "! tar -xzf data.tgz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!find data -type f -exec mv '{}' '{}'.txt \\;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sequence_length = 100\n",
    "max_char_length = 500\n",
    "embedding_dim = 100\n",
    "vocab_size = 10000\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7761 files belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = text_dataset_from_directory('data/test', label_mode='categorical', batch_size=batch_size, max_length=max_char_length, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "\n",
    "    def run(self, sentence):\n",
    "        sentence = self.remove_before_word(sentence, '@')\n",
    "        sentence = sentence.replace(\"\\\\n\", ' ')\n",
    "        sentence = sentence.replace(\"\\\\\", '')\n",
    "        return sentence\n",
    "\n",
    "    def remove_before_word(self, sentence, word):\n",
    "        try:\n",
    "            subject_index = sentence.index(word)\n",
    "            sentence = sentence[subject_index + len(word):]\n",
    "        except:\n",
    "            print(f\"HEY! No word '{word}' in {sentence[:30]}\")\n",
    "        return sentence\n",
    "\n",
    "preprocessor = Preprocessor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'the': 2, 'edu': 3, 'to': 4, 'in': 5, 'of': 6, 're': 7, 'com': 8, 'writes': 9, 'subject': 10, 'lines': 11, 'organization': 12, 'a': 13, 'is': 14, 'article': 15, 'i': 16, 'you': 17, 'and': 18, 'that': 19, 'this': 20, 'university': 21, 'it': 22, 'for': 23, 'not': 24, 'be': 25, 'posting': 26, 'cs': 27, 'atheists': 28, 'nntp': 29, 'host': 30, 'at': 31, 'morality': 32, 'dsinc': 33, 'about': 34, 'god': 35, 'vice': 36, 'ico': 37, 'tek': 38, 'with': 39, 'what': 40, 'jaeger': 41, 'jim': 42, 'on': 43, 'was': 44, 'bu': 45, 'reply': 46, 'my': 47, 'as': 48, 'or': 49, 'uiuc': 50, 'are': 51, 'some': 52, 'me': 53, 'by': 54, 'they': 55, 'inc': 56, 'have': 57, 'has': 58, 'cobb': 59, 'distribution': 60, 'were': 61, 'amusing': 62, 'timmbake': 63, 'mcl': 64, 'uk': 65, 'beauchaine': 66, 'how': 67, 'would': 68, 'think': 69, 'but': 70, 'do': 71, 'perry': 72, 'robert': 73, 'so': 74, 'christian': 75, 'we': 76, 'washington': 77, 'from': 78, 'david': 79, 'nye': 80, 'he': 81, 'which': 82, 'timmons': 83, 'mantis': 84, 'buphy': 85, 'gregg': 86, 'an': 87, 'u': 88, 'societally': 89, 'behavior': 90, 'cnsvax': 91, 'uwec': 92, 'been': 93, 'who': 94, 'agnostics': 95, 'bake': 96, 'faith': 97, 'co': 98, 'yet': 99, 'more': 100, 'if': 101, 'kodak': 102, 'evidence': 103, 'believe': 104, 'bill': 105, 'one': 106, 'de': 107, 'alexia': 108, 'lis': 109, 'mike': 110, 'because': 111, 'bozo': 112, 'many': 113, 'cbnewsj': 114, 'cb': 115, 'att': 116, 'dean': 117, 'kaflowitz': 118, 'when': 119, 'only': 120, 'could': 121, 'ucsb': 122, '1': 123, 'atheism': 124, 'islamic': 125, 'nasa': 126, 'still': 127, 'him': 128, 'can': 129, 'mathew': 130, 'james': 131, 'shit': 132, 'uucp': 133, 'all': 134, 'portal': 135, 'acceptable': 136, 'moral': 137, 'jhu': 138, 'arromdee': 139, 'department': 140, 'decision': 141, 'support': 142, 'wisconsin': 143, 'eau': 144, 'claire': 145, 'na': 146, 'world': 147, 'anything': 148, 'bobbe': 149, 'something': 150, 'dps': 151, 'halat': 152, 'christianity': 153, 'tektronix': 154, 'beaverton': 155, 'carson': 156, 'hogan': 157, 'their': 158, 'frank': 159, 'will': 160, 'love': 161, 'now': 162, 'bible': 163, 't': 164, 'healta': 165, 'saturn': 166, 'wwc': 167, 'no': 168, 'say': 169, 'rushdie': 170, 'law': 171, 'rusnews': 172, 'see': 173, 'eastman': 174, 'am': 175, 'why': 176, 'years': 177, 'than': 178, 'cwru': 179, 'did': 180, 'sandvik': 181, 'get': 182, \"what's\": 183, 'd012s658': 184, 'i3150101': 185, 'dbstu1': 186, 'rz': 187, 'tu': 188, 'bs': 189, 'belief': 190, 'go': 191, 'hell': 192, 'hq': 193, 'videocart': 194, 'ksu': 195, 'basis': 196, \"i'm\": 197, 'into': 198, 'jyusenkyou': 199, 'ken': 200, 'dept': 201, 'someone': 202, 'scott': 203, 'osrhe': 204, 'thread': 205, 'bit': 206, 'since': 207, \"don't\": 208, 'satanic': 209, 'read': 210, 'sun': 211, '18': 212, 'r': 213, 'hear': 214, \"didn't\": 215, 'x': 216, 'newsreader': 217, 'case': 218, 'dan': 219, '21': 220, 'believer': 221, 'concerned': 222, 'disposition': 223, 'beneath': 224, 'provide': 225, 'require': 226, 'personality': 227, 'given': 228, 'bears': 229, 'after': 230, 'w165w': 231, 'snake2': 232, 'wisc': 233, 'mark': 234, 'mccullough': 235, 'computer': 236, 'there': 237, 'theism': 238, 'cleveland': 239, 'following': 240, 'anti': 241, 'disagree': 242, 'bob': 243, 'b': 244, '17': 245, 'up': 246, 'kent': 247, \"can't\": 248, \"it's\": 249, 'anyway': 250, 'just': 251, 'ignore': 252, 'keith': 253, 'shoveler': 254, 'jimh': 255, 'post': 256, '4949': 257, \"o'dwyer\": 258, 'believing': 259, 'prepared': 260, 'your': 261, '20': 262, 'illinois': 263, 'urbana': 264, 'news': 265, 'between': 266, 'doing': 267, 'fact': 268, 'cause': 269, 'gulf': 270, 'war': 271, 'batman': 272, 'bmd': 273, 'trw': 274, 'well': 275, 'wrote': 276, 'biblical': 277, 'response': 278, 'fell': 279, 'bucket': 280, 'verses': 281, 'discussion': 282, \"rushdie's\": 283, 'says': 284, 'tortured': 285, 'another': 286, 'death': 287, 'had': 288, 'book': 289, 'down': 290, 'origins': 291, 'college': 292, 'those': 293, 'dogma': 294, 'boston': 295, 'physics': 296, 'reading': 297, 'view': 298, 'poori': 299, 'east': 300, 'tammy': 301, 'healy': 302, '2': 303, 'ark': 304, 'covenant': 305, 'said': 306, 'enter': 307, 'vesta': 308, 'unm': 309, 'clam': 310, 'fallacy': 311, 'faq': 312, 'once': 313, 'again': 314, 'deleted': 315, \"you're\": 316, 'hard': 317, '13': 318, 'piece': 319, 'title': 320, 'th': 321, 'schaertel': 322, '129': 323, '11853': 324, 'panther': 325, '2000': 326, 'mccullou': 327, 'real': 328, 'nothing': 329, 'andrew': 330, 'cmu': 331, 'science': 332, 'takes': 333, 'much': 334, 'might': 335, 'does': 336, 'take': 337, 'freenet': 338, 'tony': 339, 'alicea': 340, 'southern': 341, 'baptist': 342, 'convention': 343, 'freemasonry': 344, 'western': 345, 'reserve': 346, 'thought': 347, 'netcom': 348, 'maddi': 349, 'nickname': 350, 'look': 351, 'elsewhere': 352, '19': 353, 'apple': 354, 'newton': 355, 'know': 356, 'passive': 357, 'right': 358, 'mean': 359, 'shelley': 360, 'bobbys': 361, 'here': 362, 'meant': 363, 'argument': 364, '52': 365, 'ap': 366, 'mchp': 367, 'sni': 368, 'benedikt': 369, 'rosenau': 370, 'strongly': 371, 'irrational': 372, 'absolutes': 373, 'math': 374, 'deguzman': 375, '26': 376, 'decay': 377, 'c5lh4p': 378, '27k': 379, 'dfuller': 380, 'dave': 381, 'fuller': 382, 'jsn104': 383, 'psuvm': 384, 'psu': 385, 'blashephemers': 386, 'eternal': 387, '38': 388, 'his': 389, 'first': 390, 'e': 391, 'citation': 392, 'c5qgm3': 393, 'dl8': 394, 'cso': 395, 'merely': 396, 'question': 397, 'ethical': 398, 'society': 399, 'morals': 400, 'immoral': 401, 'johns': 402, 'hopkins': 403, '24': 404, '1993apr20': 405, 'hawaii': 406, 'annex': 407, 'fsu': 408, 'mayne': 409, 'wants': 410, 'minute': 411, 'rather': 412, 'made': 413, 'them': 414, 'wanted': 415, 'same': 416, 'old': 417, 'nyeda': 418, 'come': 419, 'follow': 420, 'our': 421, 'notion': 422, 'po': 423, 'm': 424, 'ryan': 425, '16': 426, 'ssauyet': 427, 'wesleyan': 428, 'd': 429, 'sauyet': 430, 'free': 431, 'agency': 432, 'darkside': 433, 'uoknor': 434, 'bil': 435, 'okcforum': 436, 'conner': 437, 'person': 438, 'constant': 439, 'rape': 440, 'though': 441, 'repost': 442, 'feel': 443, 'appears': 444, 'want': 445, '79': 446, 'week': 447, 'software': 448, 'cracks': 449, 'rafiq': 450, 'nature': 451, 'apostles': 452, 'engin': 453, 'umich': 454, 'ingles': 455, 'ray': 456, 'claim': 457, 'jesus': 458, 'over': 459, 'such': 460, 'little': 461, 'nott': 462, 'ac': 463, 'point': 464, 'nyx': 465, 'unix': 466, 'alt': 467, 'instance': 468, 'deep': 469, 'oulu': 470, 'tin': 471, 'version': 472, 'arms': 473, '930420': 474, '113512': 475, '1v3': 476, 'concentration': 477, 'camps': 478, 'fermi': 479, 'wustl': 480, 'chemical': 481, 'watstar': 482, 'uwaterloo': 483, 'ca': 484, 'phil': 485, 'trodwell': 486, '25': 487, 'waterloo': 488, 'date': 489, 'apr': 490, 'gmt': 491, 'where': 492, 'mit': 493, 'mac': 494, 'cc': 495, 'macalstr': 496, 'turin': 497, 'turambar': 498, 'utter': 499, 'misery': 500, 'strong': 501, 'macalester': 502, 'assert': 503, 'nonexistence': 504, 'toronto': 505, 'religion': 506, 'reason': 507, 'c5qt5p': 508, 'mvo': 509, 'blaze': 510, '115694': 511, 'group': 512, 'also': 513, 'benefit': 514, 'knowing': 515, 'deviant': 516, 'true': 517, 'engr': 518, 'latech': 519, 'believers': 520, '39': 521, 'geoff': 522, '15': 523, 'wonder': 524, 'risen': 525, 'students': 526, 'among': 527, 'newsgroup': 528, 'quiz': 529, 'answers': 530, '153': 531, '735242337': 532, '12': 533, 'cheribums': 534, 'make': 535, 'graven': 536, 'image': 537, 'refering': 538, 'idols': 539, 'created': 540, 'worshipped': 541, \"wasn't\": 542, 'wrodhipped': 543, 'high': 544, 'priest': 545, 'holy': 546, 'holies': 547, 'chris': 548, 'faehl': 549, 'new': 550, 'mexico': 551, 'albuquerque': 552, '88': 553, '735265296': 554, 'lo': 555, 'beckoning': 556, 'wonderful': 557, 'rule': 558, '3': 559, 'correct': 560, 'conspiracy': 561, 'correction': 562, 'consultants': 563, 'cambridge': 564, 'v1': 565, '02': 566, '50': 567, '11847': 568, 'bennett': 569, 'neil': 570, 'bcci': 571, 'adapted': 572, 'koran': 573, 'rules': 574, 'banking': 575, 'times': 576, 'august': 577, '1991': 578, \"let's\": 579, 'guy': 580, 'implies': 581, 'company': 582, '126': 583, '121': 584, '55': 585, '930419': 586, '104739': 587, '2t8': 588, '30136': 589, 'ursa': 590, 'bear': 591, 'pooh': 592, 'atoms': 593, 'objective': 594, \"aren't\": 595, 'even': 596, 'scientists': 597, 'call': 598, 'atom': 599, 'mathemat': 600, 'sponsored': 601, 'account': 602, 'school': 603, 'carnegie': 604, 'mellon': 605, 'pittsburgh': 606, 'pa': 607, '33': 608, 'po4': 609, '735196735': 610, 'lies': 611, 'hypocrisy': 612, 'dude': 613, 'admit': 614, 'people': 615, 'atheist': 616, 'oh': 617, 'usa': 618, '51': 619, 'ch981': 620, 'hela': 621, 'ins': 622, 'convening': 623, 'june': 624, 'consider': 625, 'charges': 626, 'incompatible': 627, 'quotes': 628, 'mr': 629, 'holly': 630, 'masonic': 631, 'flag': 632, 'carrier': 633, 'amuse': 634, 'y': 635, 'madhausc5rfqo': 636, '9ql': 637, 'madhaus': 638, 'hausmann': 639, 'stirrer': 640, 'connor': 641, 'sorry': 642, 'gotta': 643, 'resemblence': 644, 'prefer': 645, 'half': 646, \"bake'd\": 647, 'requests': 648, '157': 649, '735271671': 650, 'wanting': 651, 'excuse': 652, 'convert': 653, 'gonna': 654, 'damn': 655, 'hopes': 656, 'queens': 657, 'thoughts': 658, 'christians': 659, '190493224221': 660, 'any': 661, 'physical': 662, 'problems': 663, 'unlike': 664, 'smoking': 665, 'avoid': 666, 'today': 667, \"'em\": 668, 'err': 669, 'whadda': 670, 'smiley': 671, '37': 672, '1qvn1pinnj90': 673, 'various': 674, 'conners': 675, 'felt': 676, 'aggressive': 677, 'knock': 678, 'chip': 679, 'off': 680, 'shoulder': 681, 'type': 682, 'approach': 683, 'attempts': 684, 'reasoned': 685, 'wasted': 686, 'thi': 687, 'fanatism': 688, 'genocide': 689, 'siemens': 690, 'nixdorf': 691, 'ag': 692, '84': 693, '16bb6b7ca': 694, '1qv7q5': 695, 'fn4': 696, 'horus': 697, 'correlated': 698, 'str': 699, 'calculus': 700, 'mathematica': 701, 'damna': 702, 'damnation': 703, 'surrounded': 704, 'thumpers': 705, 'like': 706, 'yourself': 707, 'proven': 708, 'hellis': 709, 'seattle': 710, '735278230': 711, 'fine': 712, 'sentiments': 713, 'very': 714, 'assumed': 715, 'attack': 716, 'ad': 717, 'hominem': 718, 'sarcastic': 719, 'innuendo': 720, 'shoveled': 721, 'conveniently': 722, 'forgets': 723, 'cou': 724, '59': 725, '1qvh8tinnsg6': 726, 'yohan': 727, 'jonathan': 728, 'w': 729, 'these': 730, 'thinks': 731, 'should': 732, 'guess': 733, 'delving': 734, 'religious': 735, 'language': 736, 'area': 737, 'exactly': 738, 'never': 739, 'eating': 740, 'meat': 741, 'differentiate': 742, 'personal': 743, 'choice': 744, 'preference': 745, 'fall': 746, 'find': 747, 'compelling': 748, 'peace': 749, 'niks': 750, '102306': 751, '882': 752, 'jbrown': 753, 'liberated': 754, 'spain': 755, 'going': 756, 'until': 757, 'hit': 758, 'independent': 759, 'country': 760, 'coup': 761, 'americans': 762, 'led': 763, 'request': 764, 'us': 765, 'refused': 766, 'eventually': 767, 'several': 768, 'later': 769, 'during': 770, 'spanish': 771, 'ame': 772, 'pipe': 773, 'william': 774, 'florida': 775, 'state': 776, 'bullshit': 777, 'being': 778, 'societal': 779, '66': 780, '004119': 781, '6119': 782, 'accepted': 783, 'expect': 784, 'others': 785, 'mandated': 786, 'pardon': 787, 'extremism': 788, \"couldn't\": 789, 'murder': 790, 'nicknames': 791, 'b64635': 792, 'student': 793, '16bb6b6fe': 794, 'eagle': 795, 'okay': 796, 'anybody': 797, 'eagel': 798, 'speak': 799, 'c5pxqs': 800, 'lm5': 801, 'interested': 802, 'original': 803, 'discussing': 804, 'punish': 805, 'her': 806, 'nat': 807, '99': 808, 'last': 809, 'vanished': 810, 'appearing': 811, 'locally': 812, \"i'll\": 813, 'always': 814, 'slighted': 815, 'postings': 816, 'conversational': 817, 'rob': 818, 'dated': 819, 'however': 820, 'compelled': 821, 'respond': 822, 'delayed': 823, 'falling': 824, '114525': 825, 'promised': 826, \"zakaria's\": 827, 'called': 828, 'taken': 829, 'zakaria': 830, 'muhammad': 831, 'quran': 832, '30': 833, '1qiu97innpq6': 834, 'srvr1': 835, 'resurrection': 836, 'often': 837, 'claimed': 838, 'disciples': 839, 'beliefs': 840, 'renounce': 841, 'ba': 842, 'rescued': 843, 'furor': 844, 'discussed': 845, 'net': 846, 'generally': 847, 'comes': 848, 'contention': 849, 'hand': 850, 'tsv': 851, 'contains': 852, 'blood': 853, 'libel': 854, 'against': 855, 'islam': 856, 'merit': 857, 'least': 858, 'banning': 859, 'probably': 860, '87': 861, 'originally': 862, 'reposting': 863, \"doesn't\": 864, 'ignoring': 865, 'c4w5pv': 866, 'jxd': 867, 'stuff': 868, \"bill's\": 869, 'quote': 870, 'keywords': 871, '1993apr19': 872, '141112': 873, '15018': 874, 'eczcaw': 875, 'mips': 876, 'wainwright': 877, 'hi': 878, 'having': 879, 'lately': 880, 'theist': 881, 'acquaintance': 882, 'stated': 883, 'thousands': 884, 'bibles': 885, 'discovered': 886, 'certain': 887, 'time': 888, 'syllable': 889, 'perfect': 890, 'therefore': 891, 'mu': 892, 'du': 893, 'public': 894, 'access': 895, 'denver': 896, '1qsum1inng5k': 897, \"you've\": 898, 'missed': 899, 'exponent': 900, 'based': 901, 'anagram': 902, 'fully': 903, 'extended': 904, 'translates': 905, 'dig': 906, 'tunnels': 907, 'store': 908, 'grain': 909, 'everywhere': 910, 'prepare': 911, 'coming': 912, 'phoenix': 913, 'fi': 914, 'petri': 915, 'pihko': 916, 'finland': 917, 'pl6': 918, 'hope': 919, 'mind': 920, 'l': 921, 'selling': 922, '40': 923, 'parallel': 924, 'definitions': 925, 'bombs': 926, 'etc': 927, 'aaaahhh': 928, 'tell': 929, 'innocents': 930, 'killed': 931, 'mm': 932, 'hmm': 933, 'scheduled': 934, 'shut': 935, 'oser': 936, 'studies': 937, 'mormon': 938, 'astrophysics': 939, '5': 940, 'transcedental': 941, 'temptation': 942, 'paul': 943, 'kurtz': 944, 'good': 945, 'section': 946, 'mormonism': 947, 'o': 948, '735175045': 949, '93': 950, '23': 951, 'big': 952, 'deletions': 953, 'show': 954, 'poor': 955, 'understanding': 956, 'human': 957, 'perhaps': 958, 'prophetic': 959, 'active': 960, 'timer': 961, 'gets': 962, 'rot': 963, 'ships': 964, 'outgoing': 965, 'articles': 966, 'hole': 967, 'somewhere': 968, \"here's\": 969, '1qi156innf9n': 970, 'senator': 971, 'bedfellow': 972, 'tcbruno': 973, 'athena': 974, 'tom': 975, 'bruno': 976, 'brings': 977, 'p': 978, 'weak': 979, '14': 980, 'ever': 981, 'got': 982, 'modified': 983, 'define': 984, 'earlier': 985, 'outcome': 986, 'adam': 987, 'cooper': 988, '123': 989, '93apr20': 990, '035421edt': 991, '47719': 992, 'neat': 993, 'tgk': 994, 'todd': 995, 'kelley': 996, 'light': 997, 'happened': 998, 'waco': 999, 'need': 1000, 'chest': 1001, 'sadly': 1002, 'understandable': 1003, 'dangerous': 1004, 'yes': 1005, 'inherently': 1006, 'encourages': 1007, 'implementation': 1008, '35': 1009, \"i've\": 1010, 'articulated': 1011, 'above': 1012, 'may': 1013, 'khomeini': 1014, 'basi': 1015, '60': 1016, '11855': 1017, '116003': 1018, 'supports': 1019, 'other': 1020, 'slander': 1021, 'job': 1022, 'respect': 1023, 'titles': 1024, 'content': 1025, 'louisiana': 1026, 'tech': 1027, 'ee02': 1028, 'pl8': 1029, 'willingness': 1030, 'die': 1031, 'jones': 1032, 'documented': 1033, 'martyrdom': 1034, 'itself': 1035, 'depth': 1036, 'both': 1037, 'deluded': 1038, 'con': 1039, 'men': 1040, '36': 1041, 'c5r5c9': 1042, '69b': 1043, 'danb': 1044, 'shell': 1045, 'babcock': 1046, '75': 1047, 'mon': 1048, '1993': 1049, 'penalty': 1050, 'political': 1051, 'madison': 1052, 'sciences': 1053, '28': 1054, 'sell': 1055, 'bastard': 1056, 'information': 1057, 'place': 1058, 'ruthlessly': 1059, 'hunt': 1060, 'especially': 1061, \"they're\": 1062, 'positions': 1063, 'power': 1064, 'looked': 1065, 'back': 1066, 'asked': 1067, 'questio': 1068, 'arnold': 1069, 'bos': 1070, 'h': 1071, 'coast': 1072, 'near': 1073, 'top': 1074, 've': 1075, 'sunselect': 1076, '1r1cl7innknk': 1077, 'seem': 1078, 'particular': 1079, 'line': 1080, 'rest': 1081, 'readership': 1082, 'wha': 1083, '62': 1084, 'problem': 1085, 'objectivist': 1086, 'determine': 1087, 'status': 1088, 'truths': 1089, 'method': 1090, 'established': 1091, 'accept': 1092, 'judgements': 1093, 'reports': 1094, 'relate': 1095, 'ought': 1096, 'naturalistic': 1097, 'then': 1098, 'cannot': 1099, 'prove': 1100, 'kmr4': 1101, 'lord': 1102, 'savior': 1103, 'keresh': 1104, 'seen': 1105, 'alive': 1106, 'spread': 1107, 'word': 1108, 'jeez': 1109, 'straight': 1110, 'told': 1111, 'wait': 1112, 'three': 1113, 'days': 1114, 'midelfort': 1115, 'clinic': 1116, 'wi': 1117, 'patently': 1118, 'absurd': 1119, 'whoever': 1120, 'wishes': 1121, 'become': 1122, 'philosopher': 1123, 'must': 1124, 'learn': 1125, '10': 1126, 'poll': 1127, 'done': 1128, 'ivy': 1129, 'league': 1130, 'schools': 1131, 'reported': 1132, 'third': 1133, 'indentified': 1134, 'themselves': 1135, 'lot': 1136, 'higher': 1137, 'general': 1138, 'population': 1139, 'reasons': 1140, 'discrepancy': 1141, 'intelligent': 1142, 'younger': 1143, 'wave': 1144, 'future': 1145, '31': 1146, 'kind': 1147, 'ignorance': 1148, 'demonstrated': 1149, 'every': 1150, 'generalizations': 1151, 'popular': 1152, 'few': 1153, 'posts': 1154, 'virtually': 1155, 'burn': 1156, 'prediliction': 1157, 'shoveling': 1158, 'latest': 1159, 'arrival': 1160, 'shows': 1161, 'bills': 1162, 'bakes': 1163, 'try': 1164, 'engage': 1165, 'reasonable': 1166, 'discourse': 1167, 'while': 1168, 'flame': 1169, 'fests': 1170, 'most': 1171}\n"
     ]
    }
   ],
   "source": [
    "# Setup the tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=oov_tok, num_words=vocab_size)\n",
    "\n",
    "i = 0\n",
    "for batch in test_dataset:\n",
    "    texts, labels = batch\n",
    "    clean_texts = [preprocessor.run(text.decode(\"utf-8\")) for text in texts.numpy()]\n",
    "    tokenizer.fit_on_texts(clean_texts)\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        break\n",
    "\n",
    "print(tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[615, 335, 69, 22, 333, 97, 4, 25, 87, 616]]\n",
      "[[615, 335, 69, 22, 333, 97, 4, 25, 87, 616]]\n",
      "114,115,116,8,117,118,10,7,34,2,163,529,530,12,31,164,60,146,11,212,5,15,165,531,532,166,167,3,165,166,167,3,301,213,302,9,533,2,303,534,51,43,2,304,6,2,305,119,35,306,535,168,536,537,81,44,538,4,539,82,61,540,4,25,541,2,304,6,2,305,542,543,18,120,2,544,545,121,307,2,546,6,547,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "308,309,3,548,549,10,7,62,28,18,95,12,21,6,550,551,552,11,553,60,147,29,26,30,308,309,3,5,15,63,554,64,63,64,122,3,310,96,83,9,311,123,124,14,13,97,555,16,214,2,312,556,313,314,557,558,559,315,316,560,17,215,169,148,34,13,561,562,317,124,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "84,98,65,10,7,99,100,170,7,125,171,12,84,563,564,65,216,217,172,565,566,11,567,41,85,45,3,86,41,9,5,15,568,36,37,38,8,149,36,37,38,8,73,66,9,569,570,67,571,572,2,573,574,6,575,2,576,577,318,578,74,579,173,101,52,580,9,13,319,39,13,320,19,581,150,14,2,218,321,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "126,102,8,219,322,10,7,75,32,14,46,4,151,126,102,8,12,174,102,582,11,220,29,26,30,323,583,584,585,5,15,324,36,37,38,8,149,36,37,38,8,73,66,9,99,16,175,127,24,13,221,14,35,24,222,39,47,223,176,14,22,224,128,4,225,53,39,2,103,16,68,226,4,104,2,103,19,47,227,228,4,53,54,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "325,229,42,152,10,7,230,326,177,129,76,169,19,75,32,14,46,4,152,325,229,42,152,11,323,5,15,586,587,588,172,231,84,98,65,130,84,98,65,130,9,327,232,27,233,3,234,235,9,5,15,589,590,591,8,152,592,229,42,152,9,593,51,24,594,55,595,596,328,40,597,598,87,599,14,329,100,178,13,600,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "330,331,3,10,7,62,28,18,95,12,601,602,603,6,236,332,604,605,606,607,11,608,29,26,30,609,330,331,3,5,46,4,63,610,64,63,64,122,3,96,83,9,237,611,2,612,613,124,333,48,334,97,48,238,614,22,52,615,335,69,22,333,97,4,25,87,616,70,97,5,40,336,22,337,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "239,338,3,339,340,10,341,342,343,344,12,218,345,346,21,239,617,618,11,619,46,4,620,239,338,3,339,340,29,26,30,621,622,179,3,39,2,341,342,343,623,20,624,4,625,2,626,19,344,14,627,39,153,16,347,2,240,628,54,629,131,630,2,241,631,632,633,68,634,635,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "36,37,38,8,73,66,10,7,62,28,18,95,12,154,56,155,49,11,212,5,15,636,637,348,8,638,348,8,349,639,9,310,96,83,105,132,640,641,642,643,242,39,17,43,20,106,349,24,2,644,4,105,2,350,16,645,646,647,83,243,244,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "36,37,38,8,73,66,10,7,648,12,154,56,155,49,11,245,5,15,165,649,650,166,167,3,165,166,167,3,301,213,302,9,243,101,316,651,87,652,4,653,4,153,17,654,57,4,351,352,655,18,16,180,74,57,47,656,246,243,66,149,36,37,38,8,55,306,19,657,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "36,37,38,8,73,66,10,7,658,43,659,12,154,56,155,49,11,353,5,15,181,660,181,247,354,8,181,355,354,8,247,181,9,48,16,356,17,248,182,661,662,663,54,357,153,664,665,249,24,19,317,4,666,153,667,250,251,252,668,358,43,253,669,247,670,17,359,17,215,173,2,671,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "36,37,38,8,73,66,10,7,183,13,132,254,4,71,44,7,62,28,18,12,154,56,155,49,11,672,5,15,673,360,88,77,3,255,156,88,77,3,131,157,9,119,2,674,105,675,18,361,256,362,16,676,19,158,357,677,678,19,679,680,47,681,682,6,683,363,19,684,31,685,364,68,25,686,16,127,687,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "36,37,38,8,73,66,10,7,75,32,14,12,154,56,155,49,11,365,5,15,257,174,133,151,126,102,8,9,5,15,324,36,37,38,8,149,36,37,38,8,73,66,9,99,16,175,127,24,13,221,14,35,24,222,39,47,223,176,14,22,224,128,4,225,53,39,2,103,16,68,226,4,104,2,103,19,47,227,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "184,133,159,258,10,7,238,18,688,44,125,689,12,690,691,692,11,693,29,26,30,184,366,367,368,107,5,15,694,185,186,187,188,189,107,185,186,187,188,189,107,369,370,9,5,15,695,696,697,366,367,368,107,159,184,133,159,258,9,238,14,371,698,39,372,190,5,373,372,190,5,373,14,699,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "230,374,50,3,13,13,375,10,7,17,160,134,191,4,192,60,146,46,4,13,375,50,3,12,700,701,31,50,11,376,377,114,115,116,8,117,118,9,5,15,378,379,135,193,194,8,380,135,193,194,8,381,382,9,383,384,385,3,9,17,386,17,160,134,191,4,192,23,24,259,5,35,25,260,23,261,387,702,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "114,115,116,8,117,118,10,7,17,160,134,191,4,192,12,31,164,60,146,11,262,5,15,378,379,135,193,194,8,380,135,193,194,8,381,382,9,383,384,385,3,9,17,386,17,160,134,191,4,192,23,24,259,5,35,25,260,23,261,387,703,40,71,17,359,25,260,704,54,705,706,707,58,708,4,25,709,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "156,88,77,3,131,157,10,7,183,13,132,254,4,71,44,7,62,28,18,12,21,6,77,710,11,388,29,26,30,156,88,77,3,5,15,63,711,64,63,64,122,3,96,83,9,131,157,9,712,713,78,389,714,390,256,42,715,87,716,6,717,718,719,720,16,391,132,4,25,721,81,722,723,20,6,724,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "108,109,50,3,110,59,10,7,89,136,90,12,21,6,263,31,264,11,725,5,726,392,195,195,3,727,392,195,195,3,728,729,355,9,5,15,393,394,265,395,50,3,59,108,109,50,3,110,59,9,396,13,397,23,2,196,6,32,137,398,90,89,136,90,16,242,39,730,40,399,731,732,244,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "108,109,50,3,110,59,10,7,89,136,90,12,21,6,263,31,264,11,262,16,733,197,734,198,13,735,736,737,40,738,14,32,49,400,16,739,347,6,740,741,4,25,137,49,401,70,16,69,22,121,25,67,71,76,742,266,24,267,150,111,22,14,13,743,744,49,745,18,24,267,150,111,76,173,22,48,401,71,76,746,4,40,2,196,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "199,27,138,3,200,139,10,7,75,32,14,12,402,403,21,27,201,11,404,5,15,257,174,133,151,126,102,8,9,99,16,175,127,24,13,221,14,35,24,222,39,47,223,176,14,22,224,128,4,225,53,39,2,103,16,68,226,4,104,2,103,19,47,227,228,4,53,54,20,35,68,747,748,2,268,14,35,121,269,17,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n",
      "199,27,138,3,200,139,10,7,270,271,18,749,750,12,402,403,21,27,201,11,245,5,15,405,751,752,272,273,274,8,753,272,273,274,8,9,406,76,754,22,78,755,275,17,61,756,275,757,17,758,20,106,406,44,87,759,760,13,761,54,762,763,4,13,764,4,407,22,2,765,766,70,767,180,407,22,768,177,769,770,2,771,772,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\"tf.Tensor(1.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\",\"tf.Tensor(0.0, shape=(), dtype=float32)\"\r\n"
     ]
    }
   ],
   "source": [
    "with open('test_data.csv', 'w') as data_file:\n",
    "    writer = csv.writer(data_file)\n",
    "    i = 0\n",
    "    for batch in test_dataset:\n",
    "        texts, labels = batch\n",
    "        clean_texts = [preprocessor.run(text.decode(\"utf-8\")) for text in texts.numpy()]\n",
    "        sequences = tokenizer.texts_to_sequences(clean_texts)\n",
    "        sequences = pad_sequences(sequences, sequence_length, padding=padding_type, truncating=trunc_type)\n",
    "        writer.writerows(list(sequence) + list(label) for sequence, label in zip(sequences, labels))\n",
    "        print(tokenizer.texts_to_sequences(['people might think it takes faith to be an atheist']))\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            break\n",
    "! cat test_data.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "with open('test_data.csv', 'r') as data_file:\n",
    "    reader = csv.reader(data_file)\n",
    "    for row in reader:\n",
    "        print(len(row))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "1171"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}