{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "from lib import detection_utils as utils\n",
    "from lib.mnist_aug.mnist_augmenter import DataManager, MNISTAug\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "k = 9\n",
    "H = 112\n",
    "W = 112\n",
    "Wp = 22\n",
    "Hp = 22\n",
    "b_regions = 256\n",
    "\n",
    "threshold_p = 0.6\n",
    "threshold_n = 0.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dm = DataManager()\n",
    "dm.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "aug = MNISTAug()\n",
    "x_train, y_train = aug.get_augmented(dm.x_train, dm.y_train, 10)\n",
    "x_test, y_test = aug.get_augmented(dm.x_test, dm.y_test, 2)\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).view((-1, 1, H, W))\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32).view((-1, 1, H, W))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MnistDetector(nn.Module):\n",
    "\n",
    "    def __init__(self, k):\n",
    "        super().__init__()\n",
    "\n",
    "        self.threshold_p = 0.6\n",
    "        self.threshold_n = 0.3\n",
    "\n",
    "        self.Wp = 22\n",
    "        self.Hp = 22\n",
    "\n",
    "        self.X = 64  # Width of region\n",
    "        self.Y = 64\n",
    "\n",
    "        self.b_regions = 256\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "        self.DetectorOut = collections.namedtuple('DetectorOut', 'features confidences diffs regions_p regions_n idx_p idx_n matched_bboxes')\n",
    "        self.anchors_tensor = utils.generate_anchors(shape=(Wp, Hp), sizes=(.15, .45, .75),\n",
    "                                        ratios=(0.5, 1, 2))  # Tensor of shape (4, k*H*W) -> cy, cy, w, h\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.box_regressor = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 5 * self.k, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, y_bboxes=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ---------\n",
    "        x: tensor of shape (-1, C, H, W)\n",
    "        bboxes: (optional) list of tensors of shape (4, n)\n",
    "        \"\"\"\n",
    "        features = self.feature_extractor(x)\n",
    "        bboxes = self.box_regressor(features)\n",
    "        bboxes = bboxes.view((-1, 5, k, *bboxes.shape[-2:]))\n",
    "\n",
    "        regions_p = []\n",
    "        regions_n = []\n",
    "        idx_p_batch = []\n",
    "        idx_n_batch = []\n",
    "        best_bbox_idx_batch = []\n",
    "\n",
    "        # If training mode, then sample positives and negatives, extract regions\n",
    "        if self.training and y_bboxes is not None:\n",
    "            for i_batch in range(len(x)):\n",
    "                iou = utils.get_iou_map(y_bboxes[i], self.anchors_tensor)\n",
    "                iou = utils.raise_bbox_iou(iou, self.threshold_p)\n",
    "                iou_max, iou_argmax = torch.max(iou, 0)  # Shape (k*H*W)\n",
    "                idx_p, idx_n = utils.sample_pn_indices(iou_max, self.threshold_p, self.threshold_n, self.b_regions)\n",
    "                pred_bbox_p, pred_bbox_n = utils.get_pred_boxes(bboxes[i, 1:], self.anchors_tensor, idx_p, idx_n)  # (4, n) (cx, cy, w, h)\n",
    "                pred_bbox_p = utils.centers_to_diag(pred_bbox_p)  # shape (4, p) (x1y1x2y2)\n",
    "                pred_bbox_n = utils.centers_to_diag(pred_bbox_n)\n",
    "\n",
    "                idx_p_batch.append(idx_p)\n",
    "                idx_n_batch.append(idx_n)\n",
    "                best_bbox_idx_batch.append(iou_argmax)\n",
    "\n",
    "                # Make coordinates feature indices b/w H and W\n",
    "                multiplier = torch.tensor([self.Wp, self.Hp, self.Wp, self.Hp]).view((4, 1))\n",
    "                pred_bbox_p = (pred_bbox_p * multiplier).type(torch.int32)  # shape (4, p) (x1y1x2y2)\n",
    "                pred_bbox_n = (pred_bbox_n * multiplier).type(torch.int32)\n",
    "\n",
    "                # Make crops of features\n",
    "                regions_batch = []\n",
    "                for positive_idx in range(len(idx_p)):\n",
    "                    idx = pred_bbox_p[positive_idx]\n",
    "                    cropped = features[:, idx[0]:idx[2]+1, idx[1]:idx[3]+1]\n",
    "                    cropped = F.interpolate(cropped, (self.H, self.W), mode='bilinear')\n",
    "                    regions_batch.append(cropped)\n",
    "                regions_p.append(torch.tensor(regions_batch))\n",
    "\n",
    "                regions_batch = []\n",
    "                for negative_idx in range(len(idx_n)):\n",
    "                    idx = pred_bbox_n[negative_idx]\n",
    "                    cropped = features[:, idx[0]:idx[2]+1, idx[1]:idx[3]+1]\n",
    "                    cropped = F.interpolate(cropped, (self.H, self.W), mode='bilinear')\n",
    "                    regions_batch.append(cropped)\n",
    "                regions_n.append(torch.tensor(regions_batch))\n",
    "\n",
    "        # TODO: If eval mode, then sample top 300 confidence anchors' regions\n",
    "        if not self.training:\n",
    "            pass\n",
    "\n",
    "        return self.DetectorOut(\n",
    "            features=features,\n",
    "            confidences=bboxes[:, 0] if bboxes is not None else None,\n",
    "            diffs=bboxes[:, 1:] if bboxes is not None else None,\n",
    "            regions_p=regions_p,\n",
    "            regions_n=regions_n,\n",
    "            idx_p=idx_p_batch,\n",
    "            idx_n=idx_n_batch,\n",
    "            matched_bboxes=best_bbox_idx_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = MnistDetector(k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "def process_y_batch(y):\n",
    "    ys = []\n",
    "    for yi in y:\n",
    "        yi_ = utils.labels_to_tensor(yi, H, W)\n",
    "        iou = utils.get_iou_map(yi_, anchors_tensor)\n",
    "        iou = utils.raise_bbox_iou(iou, threshold_p)\n",
    "        iou_max, iou_argmax = torch.max(iou, 0)  # Shape (k*H*W)\n",
    "\n",
    "        confidences = utils.get_confidences(iou_max, threshold_p, (k, Hp, Wp))\n",
    "        diffs = utils.get_diffs(yi_, anchors_tensor, iou_max, iou_argmax, k, Hp, Wp)\n",
    "\n",
    "        ys.append(torch.stack((confidences, *diffs)))\n",
    "\n",
    "    return torch.stack(ys)\n",
    "\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 2\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        start_index = i\n",
    "        end_index = i+batch_size\n",
    "\n",
    "        x_batch = x_train[start_index:end_index]\n",
    "        y_batch = process_y_batch(y_train[start_index:end_index])\n",
    "\n",
    "        y_hat = model(x_batch)\n",
    "\n",
    "        indices = []\n",
    "        for j in range(batch_size):\n",
    "            idx_p, idx_n = utils.sample_pn_indices(y_hat[i][0].flatten(0), threshold_p, threshold_n, b_regions)\n",
    "            print(idx_p.shape)\n",
    "            break\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# ==================\n",
    "\n",
    "i = 0\n",
    "start_index = i\n",
    "end_index = i + batch_size\n",
    "\n",
    "x_batch = x_train[start_index:end_index]\n",
    "y_batch = y_train[start_index:end_index]\n",
    "\n",
    "# Preprocessing y_batch -----------\n",
    "confidences_batch = []\n",
    "diffs_batch = []\n",
    "\n",
    "# For each item in the batch:\n",
    "yi = y_batch[0]\n",
    "\n",
    "yi_ = utils.labels_to_tensor(yi, H, W)\n",
    "iou = utils.get_iou_map(yi_, anchors_tensor)\n",
    "iou = utils.raise_bbox_iou(iou, threshold_p)\n",
    "iou_max, iou_argmax = torch.max(iou, 0)  # Shape (k*H*W)\n",
    "\n",
    "confidences = utils.get_confidences(iou_max, threshold_p, (k, Hp, Wp))\n",
    "diffs = utils.get_diffs(yi_, anchors_tensor, iou_max, iou_argmax, k, Hp, Wp)\n",
    "\n",
    "confidences_batch.append(confidences)\n",
    "diffs_batch.append(diffs)\n",
    "\n",
    "confidences_batch = torch.stack(confidences_batch)\n",
    "diffs_batch = torch.stack(diffs_batch)\n",
    "\n",
    "# return confidences_batch, diffs_batch  # -------- END PROCESSING ----------\n",
    "\n",
    "y_hat = model(x_batch)\n",
    "\n",
    "indices = []\n",
    "for j in range(batch_size):\n",
    "    idx_p, idx_n = utils.sample_pn_indices(y_hat[i][0].flatten(0), threshold_p, threshold_n, b_regions)\n",
    "    print(idx_p.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}