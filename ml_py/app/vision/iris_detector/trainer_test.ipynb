{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhil/code/ml_gallery/ml_py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from settings import BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def plot_img(image, landmarks=None, circles=None, circles2=None, landmarks2=None):\n",
    "    \"\"\"\n",
    "    image: np.array of shape (c, h, w)\n",
    "    landmarks: np.array of shape (n, 2)\n",
    "    circles: np.array of shape (n, 3)\n",
    "    \"\"\"\n",
    "    plt.imshow(np.moveaxis(np.array(image), 0, -1))\n",
    "\n",
    "    _, h, w = image.shape\n",
    "\n",
    "    if landmarks is not None and len(landmarks) > 0:\n",
    "        x = landmarks[:, 0] * w\n",
    "        y = landmarks[:, 1] * h\n",
    "        plt.scatter(x, y)\n",
    "\n",
    "    if circles is not None and len(circles) > 0:\n",
    "        for circle in circles:\n",
    "            xc, yc, r = circle\n",
    "            plt.gca().add_patch(plt.Circle((xc, yc), r, fill=False))\n",
    "\n",
    "    if landmarks2 is not None and len(landmarks2) > 0:\n",
    "        x = landmarks2[:, 0] * w\n",
    "        y = landmarks2[:, 1] * h\n",
    "        plt.scatter(x, y, color='red')\n",
    "\n",
    "    if circles2 is not None and len(circles2) > 0:\n",
    "        for circle in circles2:\n",
    "            xc, yc, r = circle\n",
    "            plt.gca().add_patch(plt.Circle((xc, yc), r, color='red', fill=False))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transform = A.Compose (\n",
    "    [\n",
    "        # A.Resize(height=300, width=400),\n",
    "        A.RandomSizedCrop(min_max_height=(250, 250), height=300, width=400, p=0.5),\n",
    "        # A.CenterCrop(height=200, width=200),\n",
    "        A.ToGray(p=0.2),\n",
    "        A.ChannelDropout(channel_drop_range=(1, 2), p=0.2),\n",
    "        A.ChannelShuffle(p=0.2),\n",
    "        A.HueSaturationValue(p=0.2),\n",
    "        A.ImageCompression(quality_lower=60, p=0.1),\n",
    "        A.Posterize(p=0.2),\n",
    "        # A.RandomSunFlare(p=1),\n",
    "        A.Rotate(limit=40, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        # A.RandomScale(p=1),\n",
    "        # A.Lambda(image=lambda x: x/255, keypoint=lambda x: x/255),\n",
    "        A.Normalize(mean=[0,0,0], std=[1,1,1], max_pixel_value=255),\n",
    "        # ToTensorV2(),\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format='xy', remove_invisible=False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def normalize_inner_width(inner_widths: np.array):\n",
    "    return inner_widths / (400 * 0.25)\n",
    "\n",
    "def normalize_outer_width(widths: np.array):\n",
    "    return widths / (400 * 0.50)\n",
    "\n",
    "def denormalize_inner_width(inner_widths: np.array):\n",
    "    return inner_widths * (400 * 0.25)\n",
    "\n",
    "def denormalize_outer_width(widths: np.array):\n",
    "    return widths * (400 * 0.50)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class IrisImageDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_path, transform=None):\n",
    "        super(IrisImageDataset, self).__init__()\n",
    "        self.data = []\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "        self.height = 300\n",
    "        self.width = 400\n",
    "\n",
    "        with open(labels_path) as json_file:\n",
    "            self.labels = json.load(json_file)\n",
    "\n",
    "        self.image_names = sorted(list(self.labels.keys()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        label = self.labels[image_name]\n",
    "        image = Image.open(f'{self.images_dir}/{image_name}.tiff')\n",
    "        image = np.array(image)\n",
    "\n",
    "        inner_landmarks = label['inner']['landmarks']\n",
    "        outer_landmarks = label['outer']['landmarks']\n",
    "        inner_circle = label['inner'].get('circles')\n",
    "        center = [[inner_circle['xc'], inner_circle['yc']]] if inner_circle else []\n",
    "\n",
    "        landmarks = inner_landmarks + outer_landmarks + center\n",
    "\n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image=image, keypoints=landmarks)\n",
    "            image = augmentations['image']\n",
    "            landmarks = augmentations['keypoints']\n",
    "\n",
    "        n_inner = len(inner_landmarks)\n",
    "        n_outer = len(outer_landmarks)\n",
    "\n",
    "        inner = np.array(landmarks[:n_inner])\n",
    "        outer = np.array(landmarks[n_inner: n_inner + n_outer])\n",
    "        \n",
    "        labels = {\n",
    "            'inner': self.normalize_landmarks(inner).tolist(),\n",
    "            'outer': self.normalize_landmarks(outer).tolist(),\n",
    "            'center': landmarks[-1],\n",
    "            'inner_width': normalize_inner_width(self.get_width(inner)),\n",
    "            'outer_width': normalize_outer_width(self.get_width(outer)),\n",
    "            'name': image_name\n",
    "        }\n",
    "\n",
    "        # Covert from channels last to channels first\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def get_width( landmarks: np.array) -> float:\n",
    "            xs = landmarks[:, 0]\n",
    "            width = float(np.max(xs) - np.min(xs))\n",
    "            return width\n",
    "\n",
    "    def normalize_landmarks(self, landmarks):\n",
    "        return landmarks / [self.width, self.height]\n",
    "\n",
    "class IrisWidthsDataset(IrisImageDataset):\n",
    "    def __getitem__(self, index):\n",
    "        image, labels = super().__getitem__(index)\n",
    "        return image, (labels['inner_width'], labels['outer_width'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_dir = f'{BASE_DIR}/data/pupil'\n",
    "images_dir = f'{data_dir}/train/images'\n",
    "labels_path = f'{data_dir}/train/labels.json'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset = IrisWidthsDataset(images_dir=images_dir, labels_path=labels_path, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)  #, collate_fn=lambda x: x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 8, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(8, 16, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 32, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 38, 50\n",
    "\n",
    "            nn.Conv2d(32, 64, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 19, 25\n",
    "\n",
    "            nn.Conv2d(64, 128, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 10, 13\n",
    "\n",
    "            nn.Conv2d(128, 256, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 5, 7\n",
    "\n",
    "            nn.Conv2d(256, 512, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 64, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 3, 4\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.926250858761184\n",
      "9.955546074657986\n",
      "12.511601254195938\n",
      "10.654044902385301\n",
      "13.07051544098223\n",
      "7.911095046309355\n",
      "11.286894446209637\n",
      "10.17953937595911\n",
      "11.287046178105559\n",
      "14.160103127216622\n",
      "13.029746209035304\n",
      "9.756012420240307\n",
      "14.034630073652224\n",
      "11.104508263907565\n",
      "11.586050183317234\n",
      "11.877145105453973\n",
      "9.59671926446672\n",
      "9.177974738467565\n",
      "9.068739701975332\n",
      "12.232161608804683\n",
      "14.057092585925794\n",
      "12.13858868934307\n",
      "11.13666127408969\n",
      "12.344181762311019\n",
      "9.315906461620706\n",
      "11.372291973690984\n",
      "10.319932505354705\n",
      "12.561710843132232\n",
      "11.913772261283722\n",
      "10.02459680555182\n",
      "11.697000893516067\n",
      "9.591020478411924\n",
      "12.442567323176835\n",
      "10.431284680294501\n",
      "10.85898361426171\n",
      "12.22146493438548\n",
      "14.245477486465711\n",
      "13.675035960227383\n",
      "13.518501519634231\n",
      "9.585601319897025\n",
      "12.228581521406644\n",
      "9.016443899145116\n",
      "10.397096060928195\n",
      "13.659704481625845\n",
      "9.265039976673282\n",
      "12.317004822894713\n",
      "9.800954852232847\n",
      "14.881470438707474\n",
      "10.900619222573585\n",
      "9.750647918516105\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        labels = torch.stack(labels).T\n",
    "        yh = model(images)\n",
    "        loss = torch.sum(torch.abs(yh - labels))\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        print(loss.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomalies = [\n",
    "    ''\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}