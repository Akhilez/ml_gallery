{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/akhil/code/ml_gallery/ml_py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from settings import BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self,in_dim):\n",
    "        super(SelfAttention,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "\n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature\n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N)\n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "\n",
    "        out = self.gamma*out + x\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def plot_img(image, landmarks=None, circles=None, circles2=None, landmarks2=None):\n",
    "    \"\"\"\n",
    "    image: np.array of shape (c, h, w)\n",
    "    landmarks: np.array of shape (n, 2)\n",
    "    circles: np.array of shape (n, 3)\n",
    "    \"\"\"\n",
    "    plt.imshow(np.moveaxis(np.array(image), 0, -1))\n",
    "\n",
    "    _, h, w = image.shape\n",
    "\n",
    "    if landmarks is not None and len(landmarks) > 0:\n",
    "        x = landmarks[:, 0] * w\n",
    "        y = landmarks[:, 1] * h\n",
    "        plt.scatter(x, y)\n",
    "\n",
    "    if circles is not None and len(circles) > 0:\n",
    "        for circle in circles:\n",
    "            xc, yc, r = circle\n",
    "            plt.gca().add_patch(plt.Circle((xc, yc), r, fill=False))\n",
    "\n",
    "    if landmarks2 is not None and len(landmarks2) > 0:\n",
    "        x = landmarks2[:, 0] * w\n",
    "        y = landmarks2[:, 1] * h\n",
    "        plt.scatter(x, y, color='red')\n",
    "\n",
    "    if circles2 is not None and len(circles2) > 0:\n",
    "        for circle in circles2:\n",
    "            xc, yc, r = circle\n",
    "            plt.gca().add_patch(plt.Circle((xc, yc), r, color='red', fill=False))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "transform = A.Compose (\n",
    "    [\n",
    "        # A.Resize(height=300, width=400),\n",
    "        A.RandomSizedCrop(min_max_height=(250, 250), height=300, width=400, p=0.5),\n",
    "        # A.CenterCrop(height=200, width=200),\n",
    "        A.ToGray(p=0.2),\n",
    "        A.ChannelDropout(channel_drop_range=(1, 2), p=0.2),\n",
    "        A.ChannelShuffle(p=0.2),\n",
    "        A.HueSaturationValue(p=0.2),\n",
    "        A.ImageCompression(quality_lower=60, p=0.1),\n",
    "        A.Posterize(p=0.2),\n",
    "        # A.RandomSunFlare(p=1),\n",
    "        A.Rotate(limit=40, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        # A.RandomScale(p=1),\n",
    "        # A.Lambda(image=lambda x: x/255, keypoint=lambda x: x/255),\n",
    "        A.Normalize(mean=[0,0,0], std=[1,1,1], max_pixel_value=255),\n",
    "        # ToTensorV2(),\n",
    "    ],\n",
    "    keypoint_params=A.KeypointParams(format='xy', remove_invisible=False)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def normalize_inner_width(inner_widths: np.array):\n",
    "    return inner_widths / (400 * 0.25)\n",
    "\n",
    "def normalize_outer_width(widths: np.array):\n",
    "    return widths / (400 * 0.50)\n",
    "\n",
    "def denormalize_inner_width(inner_widths: np.array):\n",
    "    return inner_widths * (400 * 0.25)\n",
    "\n",
    "def denormalize_outer_width(widths: np.array):\n",
    "    return widths * (400 * 0.50)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class IrisImageDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_path, transform=None):\n",
    "        super(IrisImageDataset, self).__init__()\n",
    "        self.data = []\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_path = labels_path\n",
    "        self.transform = transform\n",
    "        self.height = 300\n",
    "        self.width = 400\n",
    "\n",
    "        with open(labels_path) as json_file:\n",
    "            self.labels = json.load(json_file)\n",
    "\n",
    "        self.image_names = sorted(list(self.labels.keys()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        label = self.labels[image_name]\n",
    "        image = Image.open(f'{self.images_dir}/{image_name}.tiff')\n",
    "        image = np.array(image)\n",
    "\n",
    "        inner_landmarks = label['inner']['landmarks']\n",
    "        outer_landmarks = label['outer']['landmarks']\n",
    "        inner_circle = label['inner'].get('circles')\n",
    "        center = [[inner_circle['xc'], inner_circle['yc']]] if inner_circle else []\n",
    "\n",
    "        landmarks = inner_landmarks + outer_landmarks + center\n",
    "\n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image=image, keypoints=landmarks)\n",
    "            image = augmentations['image']\n",
    "            landmarks = augmentations['keypoints']\n",
    "\n",
    "        n_inner = len(inner_landmarks)\n",
    "        n_outer = len(outer_landmarks)\n",
    "\n",
    "        inner = np.array(landmarks[:n_inner])\n",
    "        outer = np.array(landmarks[n_inner: n_inner + n_outer])\n",
    "        \n",
    "        labels = {\n",
    "            'inner': self.normalize_landmarks(inner).tolist(),\n",
    "            'outer': self.normalize_landmarks(outer).tolist(),\n",
    "            'center': landmarks[-1],\n",
    "            'inner_width': normalize_inner_width(self.get_width(inner)),\n",
    "            'outer_width': normalize_outer_width(self.get_width(outer)),\n",
    "            'name': image_name\n",
    "        }\n",
    "\n",
    "        # Covert from channels last to channels first\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "    @staticmethod\n",
    "    def get_width( landmarks: np.array) -> float:\n",
    "            xs = landmarks[:, 0]\n",
    "            width = float(np.max(xs) - np.min(xs))\n",
    "            return width\n",
    "\n",
    "    def normalize_landmarks(self, landmarks):\n",
    "        return landmarks / [self.width, self.height]\n",
    "\n",
    "class IrisWidthsDataset(IrisImageDataset):\n",
    "    def __getitem__(self, index):\n",
    "        image, labels = super().__getitem__(index)\n",
    "        return image, (labels['inner_width'], labels['outer_width'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_dir = f'{BASE_DIR}/data/pupil'\n",
    "images_dir = f'{data_dir}/train/images'\n",
    "labels_path = f'{data_dir}/train/labels.json'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dataset = IrisWidthsDataset(images_dir=images_dir, labels_path=labels_path, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)  #, collate_fn=lambda x: x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 8, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(8, 16, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 32, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 38, 50\n",
    "\n",
    "            nn.Conv2d(32, 64, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 19, 25\n",
    "\n",
    "            nn.Conv2d(64, 128, padding=1, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, padding=1, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            # 10, 13\n",
    "\n",
    "            SelfAttention(128),\n",
    "\n",
    "            # nn.Conv2d(128, 256, padding=1, kernel_size=3),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(256, 256, padding=1, kernel_size=3, stride=2),\n",
    "            # nn.ReLU(),\n",
    "            # # 5, 7\n",
    "            #\n",
    "            # nn.Conv2d(256, 512, padding=1, kernel_size=3),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(512, 64, padding=1, kernel_size=3, stride=2),\n",
    "            # nn.ReLU(),\n",
    "            # # 3, 4\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(128 * 10 * 13, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 2)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1930.1240234375\n",
      "  35.689876556396484 20.0\n",
      "1357.2366943359375\n",
      "  36.61941909790039 32.0\n",
      "1595.23486328125\n",
      "  33.84495544433594 65.5999984741211\n",
      "1948.83642578125\n",
      "  40.5289192199707 21.0\n",
      "1790.56787109375\n",
      "  39.96446990966797 30.123605728149414\n",
      "1486.63232421875\n",
      "  43.38674545288086 22.0\n",
      "1545.799072265625\n",
      "  47.88535690307617 84.375732421875\n",
      "2098.64501953125\n",
      "  44.93120574951172 38.29927444458008\n",
      "1742.48388671875\n",
      "  39.9792594909668 67.79517364501953\n",
      "1093.671875\n",
      "  52.542030334472656 30.144432067871094\n",
      "1909.7720947265625\n",
      "  32.50450134277344 24.0\n",
      "1439.74658203125\n",
      "  32.930877685546875 56.0\n",
      "2015.6708984375\n",
      "  33.28092956542969 41.599998474121094\n",
      "1285.7032470703125\n",
      "  42.20025634765625 42.52890396118164\n",
      "1511.5137939453125\n",
      "  40.94729232788086 23.0\n",
      "1744.6983642578125\n",
      "  34.44169616699219 62.57959747314453\n",
      "1909.86767578125\n",
      "  31.84551239013672 50.464820861816406\n",
      "1383.80419921875\n",
      "  35.61973190307617 18.0\n",
      "1517.3529052734375\n",
      "  38.111427307128906 26.0\n",
      "1573.6337890625\n",
      "  34.9378776550293 78.38623046875\n",
      "1551.581298828125\n",
      "  54.281700134277344 43.0\n",
      "1737.561279296875\n",
      "  31.18207550048828 10.0\n",
      "1321.777099609375\n",
      "  36.87873840332031 29.0\n",
      "1833.420166015625\n",
      "  35.41204071044922 56.72682189941406\n",
      "2026.364013671875\n",
      "  36.73719024658203 75.19999694824219\n",
      "1975.676513671875\n",
      "  37.6915168762207 33.599998474121094\n",
      "1222.05517578125\n",
      "  36.53820037841797 41.599998474121094\n",
      "1365.5654296875\n",
      "  38.181243896484375 24.0\n",
      "1973.4111328125\n",
      "  34.955833435058594 28.790502548217773\n",
      "1560.93212890625\n",
      "  36.162269592285156 72.0\n",
      "2347.043212890625\n",
      "  35.01448059082031 44.79999923706055\n",
      "881.6137084960938\n",
      "  33.87416076660156 14.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_loader:\n",
    "        labels = torch.stack(labels).T.float()\n",
    "        yh = model(images.float())\n",
    "        # loss = torch.nn.functional.l1_loss(yh, labels)\n",
    "        loss = torch.nn.functional.mse_loss(yh, labels)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        print(loss.item())\n",
    "        print(' ', yh[0][0].item(), labels[0][0].item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "anomalies = [\n",
    "    ''\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}