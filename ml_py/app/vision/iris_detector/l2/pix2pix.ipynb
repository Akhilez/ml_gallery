{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "from matplotlib.patches import Ellipse\n",
    "import os\n",
    "\n",
    "from settings import BASE_DIR\n",
    "\n",
    "height = 160\n",
    "width = 224\n",
    "\n",
    "\n",
    "def plot_img(image, ellipses=None, show=False):\n",
    "    \"\"\"\n",
    "    image: np.array of shape (c, h, w)\n",
    "    ellipses: np.array of shape (n, 5)\n",
    "    \"\"\"\n",
    "    plt.imshow(np.moveaxis(np.array(image), 0, -1))\n",
    "\n",
    "    _, h, w = image.shape\n",
    "\n",
    "    if ellipses is not None and len(ellipses) > 0:\n",
    "        for ellipse in ellipses:\n",
    "            xc, yc, rx, ry, a = ellipse\n",
    "            plt.gca().add_patch(\n",
    "                Ellipse(xy=(xc, yc), width=2 * rx, height=2 * ry, angle=a, fill=False)\n",
    "            )\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=height, width=width),\n",
    "        # A.RandomSizedCrop(min_max_height=(250, 250), height=300, width=400, p=0.5),\n",
    "        # A.CenterCrop(height=200, width=200),\n",
    "        # A.ToGray(p=0.2),\n",
    "        # A.ChannelDropout(channel_drop_range=(1, 2), p=0.2),\n",
    "        # A.ChannelShuffle(p=0.2),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        # A.ImageCompression(quality_lower=60, p=0.1),\n",
    "        # A.Posterize(p=0.2),\n",
    "        # A.Rotate(limit=40, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n",
    "        # A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1], max_pixel_value=255),\n",
    "    ],\n",
    "    # keypoint_params=A.KeypointParams(format=\"xy\", remove_invisible=False),\n",
    ")\n",
    "\n",
    "\n",
    "class IrisImageDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, labels_path=None, transform=None):\n",
    "        super(IrisImageDataset, self).__init__()\n",
    "        self.data = []\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.masks_path = masks_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_names = self.get_images_list(images_path, file_ext=\".png\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(f\"{self.images_path}/{image_name}.png\")\n",
    "        image = np.array(image)\n",
    "\n",
    "        mask = Image.open(f\"{self.masks_path}/{image_name}.png\")\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image=image, mask=mask)\n",
    "            image = augmentations[\"image\"]\n",
    "            mask = augmentations[\"mask\"]\n",
    "\n",
    "        # Covert from channels last to channels first\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "        mask = np.moveaxis(mask, -1, 0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    @staticmethod\n",
    "    def get_images_list(images_dir, file_ext=None):\n",
    "        files_list = sorted(os.listdir(images_dir))\n",
    "        extension_len = len(file_ext)\n",
    "        if file_ext:\n",
    "            file_list_ = []\n",
    "            for file_name in files_list:\n",
    "                if file_name[-extension_len:] == file_ext:\n",
    "                    file_list_.append(file_name[:-extension_len])\n",
    "            files_list = file_list_\n",
    "        return files_list\n",
    "\n",
    "\n",
    "data_dir = f\"{BASE_DIR}/data/pupil/L2\"\n",
    "train_images_path = f\"{data_dir}/training_set/images\"\n",
    "training_labels_path = f\"{data_dir}/training_set/ground_truth/\"\n",
    "training_masks_path = f\"{data_dir}/training_set/masks/\"\n",
    "\n",
    "dataset = IrisImageDataset(\n",
    "    images_path=train_images_path, masks_path=training_masks_path, transform=transform\n",
    ")\n",
    "train_loader = DataLoader(dataset, batch_size=3, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "for images, masks in train_loader:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}