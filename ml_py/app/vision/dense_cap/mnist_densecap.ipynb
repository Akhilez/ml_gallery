{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lib.mnist_aug.mnist_augmenter import DataManager, MNISTAug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug = MNISTAug()\n",
    "dm = DataManager()\n",
    "dm.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug.max_objects = 5\n",
    "aug.min_objects = 3\n",
    "\n",
    "x_train, y_train = aug.get_augmented(dm.x_train, dm.y_train, 2, get_captions=True)\n",
    "x_test, y_test = aug.get_augmented(dm.x_train, dm.y_train, 2, get_captions=True)\n",
    "\n",
    "DataManager.plot_num(x_train[0], y_train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "W = 112\n",
    "H = 112"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DenseCapModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.k = 9\n",
    "        self.X = 64\n",
    "        self.Y = 64\n",
    "        self.V = 100  # TODO: Set vocab size\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.rpn = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(512, 5 * self.k, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "            # sigmoid / tanh on first k, relu on the rest\n",
    "        )\n",
    "\n",
    "        self.recognition = nn.Sequential(\n",
    "            nn.Linear(self.X * self.Y * 512, 4096),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.second_rpn = nn.Linear(4096, 4096) # sigmoid / tanh on first, relu on the rest\n",
    "\n",
    "        self.rnn = nn.Sequential(\n",
    "            nn.LSTM(512, 512),  # TODO: This might be wrong\n",
    "\n",
    "            nn.Linear(512, self.V),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature_map = self.feature_extractor(x)\n",
    "\n",
    "        region_proposals = self.rpn(feature_map)\n",
    "\n",
    "        # TODO: Apply sigmoid and relu on these\n",
    "        # TODO: Project the regions to features\n",
    "        # TODO: Slice the regions in the features\n",
    "        # TODO: Apply bilinear interpolation on the slices\n",
    "        # TODO: For each region, call recognize_and_generate function\n",
    "\n",
    "    def recognize_and_generate(self, feature_map):\n",
    "        features = torch.flatten(feature_map)\n",
    "        # TODO: A relu here maybe?\n",
    "        \n",
    "        recognized = self.recognition(features)\n",
    "        \n",
    "        offsets = self.second_rpn(recognized)\n",
    "        # TODO: Apply activations\n",
    "        \n",
    "        self.rnn(recognized)\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}