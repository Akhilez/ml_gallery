{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import relu, dropout\n",
    "import numpy as np\n",
    "from lib.mnist_aug.mnist_augmenter import DataManager, MNISTAug"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug = MNISTAug()\n",
    "dm = DataManager()\n",
    "dm.load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aug.max_objects = 10\n",
    "aug.min_objects = 4\n",
    "aug.spacing = 1\n",
    "aug.scaling_mean = 1\n",
    "aug.scaling_sd = 0.25\n",
    "aug.overflow = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train = aug.get_augmented(dm.x_train, dm.y_train, 1000)\n",
    "x_test, y_test = aug.get_augmented(dm.x_test, dm.y_test, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train.reshape(-1, 1, 112, 112)).type('torch.FloatTensor')\n",
    "x_test = torch.tensor(x_test.reshape(-1, 1, 112, 112)).type('torch.FloatTensor')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_index = 3\n",
    "DataManager.plot_num(x_train[test_index].reshape((112, 112)), y_train[test_index])\n",
    "y_train[test_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def to_one_hot(x, num_classes=10):\n",
    "  b = np.zeros((len(x), num_classes), dtype=np.float32)\n",
    "  b[np.arange(len(x)), x] = 1\n",
    "  return b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_width = 112\n",
    "n_anchors_row = 4\n",
    "n_anchors = n_anchors_row ** 2\n",
    "anchor_width = 28\n",
    "anchor_grid_spacing = img_width / n_anchors_row\n",
    "\n",
    "anchor_centers = []\n",
    "for i in range(n_anchors_row):\n",
    "  anchor_row = []\n",
    "  for j in range(n_anchors_row):\n",
    "    anchor_row.append([\n",
    "      j * anchor_grid_spacing + anchor_grid_spacing / 2,\n",
    "      i * anchor_grid_spacing + anchor_grid_spacing / 2,\n",
    "    ])\n",
    "  anchor_centers.append(anchor_row)\n",
    "anchor_centers = torch.tensor(anchor_centers).reshape((-1, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_fractional_difference(anchor, bounding_box):\n",
    "  a_box = anchor\n",
    "  b_box = bounding_box\n",
    "\n",
    "  cx_d = (b_box['cx'] - a_box[0]) / img_width\n",
    "  cy_d = (b_box['cy'] - a_box[1]) / img_width\n",
    "  wd = (b_box['width'] - anchor_width) / img_width\n",
    "\n",
    "  return cx_d, cy_d, wd\n",
    "\n",
    "def get_units_from_diff(anchors, bounding_boxes):\n",
    "    diffs = torch.zeros((len(anchors), 3)).to(device)\n",
    "    for i in range(len(anchors)):\n",
    "        diffs[i][0] = bounding_boxes[i][0] * img_width + anchors[i][0]\n",
    "        diffs[i][1] = bounding_boxes[i][1] * img_width + anchors[i][1]\n",
    "        diffs[i][2] = bounding_boxes[i][2] * img_width + anchor_width\n",
    "\n",
    "    return diffs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_iou(anchor_center, bounding_box):\n",
    "\n",
    "    half_anchor_width = anchor_width / 2\n",
    "    boxA = [\n",
    "        anchor_center[0]-half_anchor_width,\n",
    "        anchor_center[1]-half_anchor_width,\n",
    "        anchor_center[0]+half_anchor_width,\n",
    "        anchor_center[1]+half_anchor_width\n",
    "    ]\n",
    "    boxB = [bounding_box['x1'], bounding_box['y1'], bounding_box['x2'], bounding_box['y2']]\n",
    "\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_positive_anchors(y_batch):\n",
    "    \"\"\"\n",
    "    1. For Each item in the batch:\n",
    "    2. For each anchor box:\n",
    "    - For each bounding box:\n",
    "        - Find the IoU.\n",
    "    - Pick bounding box with highest IoU for that anchor.\n",
    "    - # TODO: Pick the anchor with the highest IoU for that bounding box.\n",
    "    - If highest IoU is < 0.3, then continue 1.\n",
    "    # - Create the difference units for the anchor and the bounding box as y\n",
    "    - Now add the anchor box and bounding box into a map.\n",
    "    \"\"\"\n",
    "    all_positive_pairs = []\n",
    "    for batch_i in range(len(y_batch)):\n",
    "        positive_pairs_batch = []\n",
    "        max_iou_b = {}\n",
    "        max_iou_a = {}\n",
    "\n",
    "        # ---------- The two loops --------------\n",
    "\n",
    "        for anchor_i in range(len(anchor_centers)):\n",
    "            for bb_i in range(len(y_batch[batch_i])):\n",
    "\n",
    "                b_box = y_batch[batch_i][bb_i]\n",
    "                a_box = anchor_centers[anchor_i]\n",
    "\n",
    "                iou = get_iou(a_box, b_box)\n",
    "                default_iou = {'iou': 0, 'bb_i': -1, 'ab_i': -1}\n",
    "\n",
    "                # --------------- Find max IoUs ------------------\n",
    "\n",
    "                if iou > max_iou_b.get(bb_i, default_iou)['iou']:\n",
    "                    max_iou_b[bb_i] = {\n",
    "                        'iou': iou,\n",
    "                        'bb_i': bb_i,\n",
    "                        'ab_i': anchor_i\n",
    "                    }\n",
    "\n",
    "                if iou > 0.5 and iou > max_iou_a.get(anchor_i, default_iou)['iou']:\n",
    "                    max_iou_a[anchor_i] = {\n",
    "                        'iou': iou,\n",
    "                        'bb_i': bb_i,\n",
    "                        'ab_i': anchor_i\n",
    "                    }\n",
    "\n",
    "        # --------- Merge both max ious ----------------\n",
    "\n",
    "        positive_pairs = [max_iou_b[index] for index in list(max_iou_b.keys())]\n",
    "        for index in list(max_iou_a.keys()):\n",
    "            if max_iou_a[index] not in positive_pairs:\n",
    "                positive_pairs.append(max_iou_a[index])\n",
    "        all_positive_pairs.append(positive_pairs)\n",
    "\n",
    "    return all_positive_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positives = get_positive_anchors(y_test[:2])\n",
    "for positive in positives:\n",
    "  print(len(positive))\n",
    "n_anchors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_y_d(y):\n",
    "  \"\"\"\n",
    "  Find all the positive anchor pairs.\n",
    "  for each of y:\n",
    "    for each pair in yi:\n",
    "      find fractional difference in anchor and bounding box.\n",
    "      append the fractional difference to the pair.\n",
    "  \"\"\"\n",
    "  y_d = []\n",
    "  positive_pairs = get_positive_anchors(y)\n",
    "  for yi in range(len(y)):\n",
    "    diffs = []\n",
    "    for pair_i in range(len(y[yi])):\n",
    "      pair = positive_pairs[yi][pair_i]\n",
    "      anchor = anchor_centers[pair['ab_i']]\n",
    "      bounding_box = y[yi][pair['bb_i']]\n",
    "      cx_d, cy_d, wd = get_fractional_difference(anchor, bounding_box)\n",
    "      diffs.append((cx_d, cy_d, wd, pair['ab_i'], pair['bb_i']))\n",
    "    y_d.append(torch.tensor(diffs))\n",
    "  return y_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_d = get_y_d(y_train)\n",
    "y_test_d = get_y_d(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_training = True\n",
    "drop_p = 0.3\n",
    "\n",
    "\n",
    "class BoxPredictor(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.linear1 = torch.nn.Linear(1024, 512)\n",
    "    self.linear2 = torch.nn.Linear(512, 3 * n_anchors)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = dropout(relu(self.linear1(x)), drop_p, is_training)\n",
    "    x = torch.tanh(self.linear2(x))\n",
    "    return x.reshape((-1, n_anchors, 3))\n",
    "\n",
    "\n",
    "class ConfidencePredictor(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.linear1 = torch.nn.Linear(1024, 512)\n",
    "    self.linear2 = torch.nn.Linear(512, n_anchors)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = dropout(torch.relu(self.linear1(x)), drop_p, is_training)\n",
    "    x = torch.sigmoid(self.linear2(x))\n",
    "    return x\n",
    "\n",
    "\n",
    "class DetectorV1 (torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(10, 20, 3, stride=2, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(20, 40, 3, stride=2)\n",
    "        self.conv4 = torch.nn.Conv2d(40, 80, 3, stride=2, padding=1)\n",
    "        self.conv5 = torch.nn.Conv2d(80, 160, 3, stride=2)\n",
    "        self.linear1 = torch.nn.Linear(5760, 1024)\n",
    "        self.box_predictor = BoxPredictor()\n",
    "        self.confidence_predictor = ConfidencePredictor()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = relu(self.conv1(x))\n",
    "        x = relu(self.conv2(x))\n",
    "        x = relu(self.conv3(x))\n",
    "        x = relu(self.conv4(x))\n",
    "        x = relu(self.conv5(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = dropout(relu(self.linear1(x)), drop_p, is_training)\n",
    "        boxes = self.box_predictor(x)\n",
    "        confidences = self.confidence_predictor(x)\n",
    "        return boxes, confidences\n",
    "\n",
    "model = DetectorV1().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Steps:\n",
    " - get the predictions.\n",
    " - Find the anchors which have >0.1 IoU -> +ve anchors\n",
    " - Find the matching bounding box for each +ve anchor\n",
    " - All +ve anchors are high confidence, rest are low.\n",
    " - What is the loss for -ve anchors?\n",
    "\n",
    "\n",
    " - For each of the positive anchors, Find loss and add it to the total loss.\n",
    " - Find loss of the confidences.\n",
    " -\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 16\n",
    "is_training = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        start_index = i\n",
    "        end_index = i+batch_size\n",
    "\n",
    "        x_batch = x_train[start_index:end_index].to(device)\n",
    "        y_batch = y_train_d[start_index:end_index]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat_boxes, y_hat_confidences = model(x_batch)\n",
    "\n",
    "        loss = 0\n",
    "        for batch_i in range(len(y_batch)):  # Each image\n",
    "            y_diffs = y_batch[batch_i]\n",
    "            \"\"\"\n",
    "            1. find losses for each positive anchor\n",
    "            2. Sum them all up.\n",
    "            3. Create an array of n_anchors length for target confidences.\n",
    "            4. Make confidences 1 for positive indices.\n",
    "            5. Find losses for confidences.\n",
    "            \"\"\"\n",
    "            y_confidences = torch.zeros((n_anchors)).to(device)\n",
    "            for anchor_i in range(len(y_batch[batch_i])):  # Each positive anchor\n",
    "                box_index = int(y_batch[batch_i][anchor_i][4])\n",
    "                yd_box = y_batch[batch_i][anchor_i][:3].to(device)\n",
    "\n",
    "                anchor_index = int(y_batch[batch_i][anchor_i][3])\n",
    "                yd_pred = y_hat_boxes[batch_i][anchor_index]\n",
    "\n",
    "                loss += sum((yd_box - yd_pred) ** 2)\n",
    "\n",
    "                y_confidences[anchor_index] = 1.0\n",
    "\n",
    "            loss += sum((y_confidences - y_hat_confidences[batch_i]) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}\\tloss: {float(loss)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- get predictions\n",
    "- get all anchor indices where confidences are > 0\n",
    "- Find the coordinates of the boxes.\n",
    "- Do nms on those.\n",
    "- plot them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    is_training = False\n",
    "    y_hat_boxes, y_hat_confidences = model(x_test.to(device))\n",
    "    for batch_i in range(len(x_test)):\n",
    "        positive_indices = (y_hat_confidences[batch_i] > 0.7).nonzero().reshape((-1))\n",
    "\n",
    "        pred_boxes = y_hat_boxes[batch_i][positive_indices]\n",
    "        anchors = anchor_centers[positive_indices]\n",
    "        pred_confidences = y_hat_confidences[batch_i][positive_indices]\n",
    "        pred_boxes = get_units_from_diff(anchors, pred_boxes)\n",
    "\n",
    "        pred_boxes = torch.tensor([[\n",
    "            float(box[0] - box[2] / 2),\n",
    "            float(box[1] - box[2] / 2),\n",
    "            float(box[0] + box[2] / 2),\n",
    "            float(box[1] + box[2] / 2)\n",
    "         ] for box in pred_boxes]).to(device)\n",
    "\n",
    "        #keep_indices = torchvision.ops.nms(pred_boxes, pred_confidences, 0.1)\n",
    "        #pred_boxes = pred_boxes[keep_indices]\n",
    "\n",
    "        DataManager.plot_num(\n",
    "            x_test[batch_i].reshape((img_width, img_width)),\n",
    "            [{'x1': box[0], 'y1': box[1], 'x2': box[2], 'y2': box[3]} for box in pred_boxes] # + y_test[batch_i]\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}