{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Selective_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNygx9/K8/6qj6uSA5czdOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "575852d7425a437c8dfcad9b12442680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_923a3c8a27db494d9f5626be0e5bec7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06e672f59fef4cd4a1ac2d4aa8b74050",
              "IPY_MODEL_68af874895b64df18188e175420ff75b"
            ]
          }
        },
        "ef9d7d5f9f534cc7948e8237c89804e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b93fa3a8095a423b8e9274beb3b12ce9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29c46171798847f69a4076e2ffe28c51",
              "IPY_MODEL_87a054f0f1ae417f9cfa6bc243862525"
            ]
          }
        },
        "f194dbdeed4f438591dcce6ec054f240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08e090352aad4847937de69638289433",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92e5e778b3674cb1903fc5bbb6dfade5",
              "IPY_MODEL_ccf327d766a047baab79a5ce2595ce35"
            ]
          }
        },
        "075b192367b940e2886284d1a5ad4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12c2874252c2488294107e374ef5144f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88ed8253044e46a4a23ac77328b0c5ac",
              "IPY_MODEL_183543e4934f40d695416c03c9ab6503"
            ]
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akhilez/ml_gallery/blob/master/ml_py/MLGallery/selective_generator/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fYjdUPs9G8T",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "```yaml\n",
        "Generator:\n",
        "  - Input: 100 (90 noise, 10 one-hot)\n",
        "  - h1: 150\n",
        "  - h2: 400\n",
        "  - h3: 784\n",
        "\n",
        "FeatureExtractor:\n",
        "  - Input: 784 (28x28)\n",
        "  - h1: 400\n",
        "  - h2: 150\n",
        "  - h3: 100\n",
        "\n",
        "Discriminator:\n",
        "  - Input: 100\n",
        "  - h1: 50\n",
        "  - h2: 1\n",
        "\n",
        "Classifier:\n",
        "  - Input: 100\n",
        "  - h1: 50\n",
        "  - h2: 10\n",
        "```\n",
        "\n",
        "Link to file: https://github.com/Akhilez/ml_gallery/blob/master/ml_py/MLGallery/selective_generator/colab.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b83FOSP76d5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.functional import dropout, leaky_relu, binary_cross_entropy, softmax\n",
        "from torch import sigmoid\n",
        "from torch.nn import Conv2d, Linear, ConvTranspose2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eksbSQK7mXqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "826b3e3f-bb61-4cb9-8b76-afa52a4aaf78"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCLZ8YdE62Ls",
        "colab_type": "code",
        "outputId": "e615271b-8e1e-4faa-da94-afa8cfccf011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "575852d7425a437c8dfcad9b12442680",
            "ef9d7d5f9f534cc7948e8237c89804e1",
            "f194dbdeed4f438591dcce6ec054f240",
            "075b192367b940e2886284d1a5ad4b1a"
          ]
        }
      },
      "source": [
        "data_path = \"./data/mnist/\"\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(data_path, train=True, download=True,\n",
        "                               transform=torchvision.transforms.ToTensor()), shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    torchvision.datasets.MNIST(data_path, train=False, download=True,\n",
        "                               transform=torchvision.transforms.ToTensor()), shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "575852d7425a437c8dfcad9b12442680",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef9d7d5f9f534cc7948e8237c89804e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f194dbdeed4f438591dcce6ec054f240",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "075b192367b940e2886284d1a5ad4b1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/mnist/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXTQzaxc69HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_one_hot(x):\n",
        "    b = np.zeros((len(x), 10))\n",
        "    b[np.arange(len(x)), x] = 1\n",
        "    return b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXZQQySl6-YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for data in test_loader:\n",
        "    x_test.append(data[0].reshape(1, 28, 28).numpy())\n",
        "    y_test.append(data[1][0])\n",
        "\n",
        "y_test = torch.Tensor(to_one_hot(y_test))\n",
        "x_test = torch.Tensor(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJBBvGHb7CE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for data in test_loader:\n",
        "    x_train.append(data[0].reshape(1, 28, 28).numpy())\n",
        "    y_train.append(data[1][0])\n",
        "\n",
        "y_train = torch.Tensor(to_one_hot(y_train))\n",
        "x_train = torch.Tensor(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDJi3hQ37rv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train[:5000]\n",
        "x_test = x_test[:500]\n",
        "y_train = y_train[:5000]\n",
        "y_test = y_test[:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsnNSYDf7DuV",
        "colab_type": "code",
        "outputId": "3f127f21-0f4a-48ca-8abb-4336202dc793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "print(torch.min(x_test))\n",
        "print(torch.max(x_test))\n",
        "\n",
        "print(y_train[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 1, 28, 28]) torch.Size([100, 1, 28, 28]) torch.Size([1000, 10]) torch.Size([100, 10])\n",
            "tensor(0.)\n",
            "tensor(1.)\n",
            "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myqyq81i7L6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(x):\n",
        "    plt.imshow(x, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZva4kv37yDZ",
        "colab_type": "code",
        "outputId": "39441e87-af61-419b-fbfc-bfba39f9deab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "index = 13\n",
        "plot_image(x_test[index].numpy().reshape((28, 28)))\n",
        "print(y_test[index])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y14YSTRg7zR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random(shape, min_=-0.5, max_=0.5):\n",
        "    return torch.FloatTensor(*shape).uniform_(min_, max_).requires_grad_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF-ZsF-_71r_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "        # torch.nn.Linear(in_features, out_features, bias=True)\n",
        "        # torch.nn.functional.leaky_relu(input, negative_slope=0.01, inplace=False) → Tensor\n",
        "        # torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
        "\n",
        "        self.fc1 = Linear(100, 128 * 7 * 7)\n",
        "        self.conv1 = ConvTranspose2d(128, 128, 4, stride=2, padding=1)  # [2, 128, 14, 14]\n",
        "        self.conv2 = ConvTranspose2d(128, 128, 4, stride=2, padding=1)  # [2, 128, 28, 28]\n",
        "        self.conv3 = ConvTranspose2d(128, 1, 7, padding=3)\n",
        "\n",
        "    \n",
        "    def forward(self, x, **kwargs):\n",
        "        # x.shape = (batch, 100)\n",
        "        h1 = leaky_relu(self.fc1(x))\n",
        "        h1 = h1.reshape(-1, 128, 7, 7)\n",
        "        h2 = leaky_relu(self.conv1(h1))\n",
        "        h3 = leaky_relu(self.conv2(h2))\n",
        "        h4 = sigmoid(self.conv3(h3))\n",
        "        return h4\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return [{'params': layer.parameters()} for layer in (self.fc1, self.conv1, self.conv2, self.conv3)]\n",
        "\n",
        "    @staticmethod\n",
        "    def getGeneratorInput(y, batch_size):\n",
        "        gen_input = np.random.uniform(0, 1, (batch_size, 100))\n",
        "        for batch in range(batch_size):\n",
        "            for i in range(0, 1, 20):\n",
        "                gen_input[batch][i: i+10] = y[batch]\n",
        "        return torch.Tensor(gen_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V_6Faq9cCZa",
        "colab_type": "code",
        "outputId": "80bddd75-c0f5-4c1d-dc32-eeb4922e43b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "y_sample = y_test[10:12]\n",
        "print(y_sample)\n",
        "Generator.getGeneratorInput(y_sample, 2)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.7245, 0.1807, 0.3454, 0.7086, 0.7850, 0.7277, 0.4755, 0.6108,\n",
              "         0.3002, 0.6356, 0.6284, 0.3461, 0.8617, 0.8454, 0.6955, 0.2209, 0.2478,\n",
              "         0.4248, 0.8414, 0.8637, 0.9701, 0.7222, 0.9232, 0.0798, 0.5862, 0.8655,\n",
              "         0.8578, 0.5908, 0.7764, 0.7269, 0.6992, 0.3431, 0.4315, 0.7330, 0.1612,\n",
              "         0.5681, 0.0571, 0.8677, 0.8184, 0.6239, 0.2995, 0.2296, 0.9342, 0.4927,\n",
              "         0.4469, 0.5700, 0.6622, 0.3178, 0.2861, 0.6581, 0.3095, 0.7258, 0.1199,\n",
              "         0.8117, 0.0417, 0.3700, 0.7729, 0.5036, 0.0620, 0.9065, 0.4418, 0.2037,\n",
              "         0.5609, 0.2955, 0.7349, 0.8021, 0.4133, 0.9679, 0.3455, 0.9565, 0.9492,\n",
              "         0.8492, 0.2820, 0.8422, 0.8057, 0.4707, 0.6981, 0.6725, 0.0768, 0.8997,\n",
              "         0.6883, 0.5176, 0.2001, 0.6524, 0.1573, 0.3972, 0.2853, 0.7556, 0.9820,\n",
              "         0.6268],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
              "         0.0000, 0.1267, 0.3879, 0.9685, 0.6122, 0.7035, 0.5488, 0.6012, 0.5385,\n",
              "         0.1152, 0.4035, 0.9069, 0.4146, 0.1442, 0.5261, 0.9229, 0.0286, 0.8536,\n",
              "         0.8426, 0.5350, 0.8964, 0.7343, 0.0139, 0.1460, 0.6710, 0.3016, 0.8034,\n",
              "         0.9442, 0.2675, 0.8733, 0.0611, 0.5276, 0.5528, 0.8689, 0.3038, 0.4325,\n",
              "         0.8433, 0.8670, 0.0935, 0.9720, 0.1858, 0.0656, 0.5057, 0.4043, 0.2667,\n",
              "         0.6113, 0.1135, 0.1022, 0.4668, 0.5158, 0.6032, 0.7402, 0.6403, 0.7298,\n",
              "         0.5204, 0.1276, 0.8767, 0.7971, 0.2158, 0.2156, 0.2890, 0.5992, 0.4757,\n",
              "         0.4687, 0.3576, 0.9996, 0.8000, 0.4696, 0.0816, 0.3263, 0.7109, 0.8368,\n",
              "         0.6132, 0.0761, 0.7642, 0.2963, 0.5211, 0.9811, 0.1293, 0.8168, 0.0879,\n",
              "         0.7758, 0.1438, 0.5531, 0.3563, 0.9223, 0.0606, 0.2256, 0.9799, 0.1599,\n",
              "         0.4098]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7UwJDNg79tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeatureExtractor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.w1, self.b1 = get_random((784, 600)), torch.zeros(600, requires_grad=True)\n",
        "        self.w2, self.b2 = get_random((600, 600)), torch.zeros(600, requires_grad=True)\n",
        "        self.w3, self.b3 = get_random((600, 100)), torch.zeros(100, requires_grad=True)\n",
        "    \n",
        "    def forward(self, x, **kwargs):\n",
        "        h1 = sigmoid(x.matmul(self.w1) + self.b1)\n",
        "        h2 = sigmoid(h1.matmul(self.w2) + self.b2)\n",
        "        h3 = sigmoid(h2.matmul(self.w3) + self.b3)\n",
        "        return h3\n",
        "    \n",
        "    def optimize(self, lr):\n",
        "        \n",
        "        self.w1 = (self.w1 - lr * self.w1.grad).detach().requires_grad_()\n",
        "        self.w2 = (self.w2 - lr * self.w2.grad).detach().requires_grad_()\n",
        "        self.w3 = (self.w3 - lr * self.w3.grad).detach().requires_grad_()\n",
        "        \n",
        "        self.b1 = (self.b1 - lr * self.b1.grad).detach().requires_grad_()\n",
        "        self.b2 = (self.b2 - lr * self.b2.grad).detach().requires_grad_()\n",
        "        self.b3 = (self.b3 - lr * self.b3.grad).detach().requires_grad_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTpDal2i7_dy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = torch.nn.Conv2d(1, 64, 3, stride=2, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(64, 64, 3, stride=2, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(3136, 2)\n",
        "    \n",
        "    def forward(self, x, **kwargs):\n",
        "\n",
        "        h1 = dropout(leaky_relu(self.conv1(x)))  # TODO: Add dropout\n",
        "        h2 = dropout(leaky_relu(self.conv2(h1)))\n",
        "        h2 = h2.reshape(h2.shape[0], -1)  # Flatten\n",
        "        h3 = softmax(self.fc1(h2))\n",
        "\n",
        "        return h3\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return [{'params': layer.parameters()} for layer in (self.conv1, self.conv2, self.fc1)]\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_labels(sample_size, real=True):\n",
        "        labels = torch.zeros((sample_size, 2))\n",
        "        for sample in labels:\n",
        "            sample[0] = 1 if real else 0\n",
        "            sample[1] = 0 if real else 1\n",
        "        return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR1hTfa-qWiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0509b9a2-3e01-4797-e7ec-29f4d8b8e1db"
      },
      "source": [
        "Discriminator.generate_labels(batch_size, real=False)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.],\n",
              "        [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svpWhbN08BZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.w1, self.b1 = get_random((784, 600)), torch.zeros(600, requires_grad=True)\n",
        "        self.w2, self.b2 = get_random((600, 600)), torch.zeros(600, requires_grad=True)\n",
        "        self.w3, self.b3 = get_random((600, 10)), torch.zeros(10, requires_grad=True)\n",
        "    \n",
        "    def forward(self, x, **kwargs):\n",
        "        h1 = sigmoid(x.matmul(self.w1) + self.b1)\n",
        "        h2 = sigmoid(h1.matmul(self.w2) + self.b2)\n",
        "        h3 = softmax(h2.matmul(self.w3) + self.b3)\n",
        "        return h3\n",
        "    \n",
        "    def optimize(self, lr):\n",
        "        self.w1 = (self.w1 - lr * self.w1.grad).detach().requires_grad_()\n",
        "        self.w2 = (self.w2 - lr * self.w2.grad).detach().requires_grad_()\n",
        "        self.w3 = (self.w3 - lr * self.w3.grad).detach().requires_grad_()\n",
        "        \n",
        "        self.b1 = (self.b1 - lr * self.b1.grad).detach().requires_grad_()\n",
        "        self.b2 = (self.b2 - lr * self.b2.grad).detach().requires_grad_()\n",
        "        self.b3 = (self.b3 - lr * self.b3.grad).detach().requires_grad_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SWj9V7vL-o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Gan(torch.nn.Module):\n",
        "    def __init__(self, generator, discriminator):\n",
        "        super().__init__()\n",
        "        self.g = generator\n",
        "        self.d = discriminator\n",
        "\n",
        "    def forward(self, x, real=False):\n",
        "        if real:\n",
        "            self.d(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7MnX8wr8C1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fe = FeatureExtractor()\n",
        "# classifier = Classifier()\n",
        "discriminator = Discriminator().to(device)\n",
        "generator = Generator().to(device)\n",
        "\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyzrb6pIXOa8",
        "colab_type": "text"
      },
      "source": [
        "## GAN Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2iSAwOUXQlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_d():\n",
        "\n",
        "    batch_size = 200\n",
        "    losses = [0, 0]\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        start_index = i\n",
        "        end_index = i+batch_size\n",
        "        \n",
        "        x_batch = x_train[start_index:end_index].to(device)\n",
        "        y_batch = y_train[start_index:end_index]\n",
        "\n",
        "        real = Discriminator.generate_labels(batch_size).to(device)\n",
        "        fake = Discriminator.generate_labels(batch_size, real=False).to(device)\n",
        "    \n",
        "        \n",
        "        # ------------ Train with real image ----------------\n",
        "\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        discriminator_out = discriminator(x_batch)\n",
        "        \n",
        "        loss_discriminator_real = binary_cross_entropy(discriminator_out, real)\n",
        "\n",
        "        # --------------- Train with fake image -------------------\n",
        "\n",
        "        generator_input = Generator.getGeneratorInput(y_batch, batch_size).to(device)\n",
        "        \n",
        "        generated = generator(generator_input)\n",
        "        discriminator_out = discriminator(generated)\n",
        "        \n",
        "        loss_discriminator = binary_cross_entropy(discriminator_out, fake)\n",
        "        \n",
        "        # ---------------- Optimize --------------------\n",
        "\n",
        "        loss = loss_discriminator_real + loss_discriminator\n",
        "\n",
        "        loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        losses[0] += float(loss_discriminator_real)\n",
        "        losses[1] += float(loss_discriminator)\n",
        "\n",
        "        # if i % 100 == 0:\n",
        "            # print(f'        losses: {(float(loss_discriminator_real), float(loss_discriminator))}')\n",
        "        \n",
        "    print(f'  D Losses: {losses}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9r513zXdyGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_g():\n",
        "\n",
        "    batch_size = 200\n",
        "\n",
        "    losses = 0\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        start_index = i\n",
        "        end_index = i+batch_size\n",
        "        \n",
        "        x_batch = x_train[start_index:end_index]\n",
        "        y_batch = y_train[start_index:end_index]\n",
        "\n",
        "        real = Discriminator.generate_labels(batch_size).to(device)\n",
        "    \n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "        generator_input = Generator.getGeneratorInput(y_batch, batch_size).to(device)\n",
        "        \n",
        "        generated = generator(generator_input)\n",
        "        discriminator_out = discriminator(generated)\n",
        "\n",
        "        loss_generator = binary_cross_entropy(discriminator_out, real)\n",
        "        \n",
        "        loss_generator.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        losses += float(loss_generator)\n",
        "\n",
        "        # if i % 100 == 0:\n",
        "            # print(f'        losses: {float(loss_generator)}')\n",
        "            \n",
        "    print(f'  G Losses: {losses}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4B7bzv-izSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02548179-39a0-4582-e40c-41a0699460bc"
      },
      "source": [
        "epochs = 50\n",
        "losses = [0, 0]\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch: {epoch}')\n",
        "    if epoch % 10 == 0:\n",
        "        train_d()\n",
        "    train_g()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  D Losses: [2.9009516835212708, 2.5694135427474976]\n",
            "  G Losses: 2.656028300523758\n",
            "Epoch: 1\n",
            "  G Losses: 1.2676369547843933\n",
            "Epoch: 2\n",
            "  G Losses: 1.2775112986564636\n",
            "Epoch: 3\n",
            "  G Losses: 1.2789261937141418\n",
            "Epoch: 4\n",
            "  G Losses: 1.2756428122520447\n",
            "Epoch: 5\n",
            "  G Losses: 1.2691766321659088\n",
            "Epoch: 6\n",
            "  G Losses: 1.281274139881134\n",
            "Epoch: 7\n",
            "  G Losses: 1.279291719198227\n",
            "Epoch: 8\n",
            "  G Losses: 1.271279662847519\n",
            "Epoch: 9\n",
            "  G Losses: 1.2690344750881195\n",
            "Epoch: 10\n",
            "  D Losses: [2.530480772256851, 4.5395229160785675]\n",
            "  G Losses: 6.400903105735779\n",
            "Epoch: 11\n",
            "  G Losses: 6.39644467830658\n",
            "Epoch: 12\n",
            "  G Losses: 6.393760442733765\n",
            "Epoch: 13\n",
            "  G Losses: 6.422759294509888\n",
            "Epoch: 14\n",
            "  G Losses: 6.4287790060043335\n",
            "Epoch: 15\n",
            "  G Losses: 6.409407377243042\n",
            "Epoch: 16\n",
            "  G Losses: 6.389157295227051\n",
            "Epoch: 17\n",
            "  G Losses: 6.421555161476135\n",
            "Epoch: 18\n",
            "  G Losses: 6.431598424911499\n",
            "Epoch: 19\n",
            "  G Losses: 6.380217432975769\n",
            "Epoch: 20\n",
            "  D Losses: [1.5611878708004951, 1.8806900382041931]\n",
            "  G Losses: 6.138464450836182\n",
            "Epoch: 21\n",
            "  G Losses: 6.121037602424622\n",
            "Epoch: 22\n",
            "  G Losses: 6.1276936531066895\n",
            "Epoch: 23\n",
            "  G Losses: 6.13356351852417\n",
            "Epoch: 24\n",
            "  G Losses: 6.087881565093994\n",
            "Epoch: 25\n",
            "  G Losses: 6.084750175476074\n",
            "Epoch: 26\n",
            "  G Losses: 6.143603086471558\n",
            "Epoch: 27\n",
            "  G Losses: 6.1454774141311646\n",
            "Epoch: 28\n",
            "  G Losses: 6.116373300552368\n",
            "Epoch: 29\n",
            "  G Losses: 6.074029207229614\n",
            "Epoch: 30\n",
            "  D Losses: [0.24923383072018623, 1.0435508415102959]\n",
            "  G Losses: 15.339723110198975\n",
            "Epoch: 31\n",
            "  G Losses: 15.403182983398438\n",
            "Epoch: 32\n",
            "  G Losses: 15.282775640487671\n",
            "Epoch: 33\n",
            "  G Losses: 15.36514401435852\n",
            "Epoch: 34\n",
            "  G Losses: 15.363939046859741\n",
            "Epoch: 35\n",
            "  G Losses: 15.33155107498169\n",
            "Epoch: 36\n",
            "  G Losses: 15.321328163146973\n",
            "Epoch: 37\n",
            "  G Losses: 15.345332622528076\n",
            "Epoch: 38\n",
            "  G Losses: 15.250502109527588\n",
            "Epoch: 39\n",
            "  G Losses: 15.2605299949646\n",
            "Epoch: 40\n",
            "  D Losses: [0.2576179727911949, 0.1315015573054552]\n",
            "  G Losses: 23.547292709350586\n",
            "Epoch: 41\n",
            "  G Losses: 23.52880573272705\n",
            "Epoch: 42\n",
            "  G Losses: 23.67503309249878\n",
            "Epoch: 43\n",
            "  G Losses: 23.515116691589355\n",
            "Epoch: 44\n",
            "  G Losses: 23.519692420959473\n",
            "Epoch: 45\n",
            "  G Losses: 23.645609855651855\n",
            "Epoch: 46\n",
            "  G Losses: 23.51500368118286\n",
            "Epoch: 47\n",
            "  G Losses: 23.55954360961914\n",
            "Epoch: 48\n",
            "  G Losses: 23.638808250427246\n",
            "Epoch: 49\n",
            "  G Losses: 23.447319984436035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdos9mWoaCcU",
        "colab_type": "code",
        "outputId": "4afea4c2-45d9-4c58-98a4-1a5d6810f744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    index = 33\n",
        "    batch_size = 2\n",
        "    \n",
        "    x_sample = x_test[index:index+batch_size].to(device)\n",
        "    y_sample = y_test[index:index+batch_size]\n",
        "\n",
        "    generator_input = Generator.getGeneratorInput(y_sample, batch_size).to(device)\n",
        "\n",
        "    generated = generator(generator_input)\n",
        "    discriminator_out = discriminator(generated)\n",
        "    \n",
        "    real_discriminator_out = discriminator(x_sample)\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        plot_image(generated[i].reshape((28, 28)).cpu())\n",
        "        plt.show()\n",
        "        plot_image(x_sample[i].reshape((28, 28)).cpu())\n",
        "        plt.show()\n",
        "        \n",
        "    \n",
        "    print(f\"Discriminator_out fake: {discriminator_out}\\nReal Img Discriminator Out: {real_discriminator_out}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator_out fake: tensor([[5.7335e-03, 9.9427e-01],\n",
            "        [6.9326e-04, 9.9931e-01]], device='cuda:0')\n",
            "Real Img Discriminator Out: tensor([[1.0000e+00, 6.6925e-08],\n",
            "        [9.9999e-01, 1.3373e-05]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrS5g9M2XTv7",
        "colab_type": "text"
      },
      "source": [
        "# Selective GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVU0vV5_8ETE",
        "colab_type": "code",
        "outputId": "fb90d5bc-b38d-4137-a791-5d920e0d9478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "batch_size = 200\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch: {epoch}')\n",
        "    losses = [0, 0, 0, 0]\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        start_index = i\n",
        "        end_index = i+batch_size\n",
        "        \n",
        "        x_batch = x_train[start_index:end_index]\n",
        "        y_batch = y_train[start_index:end_index]\n",
        "    \n",
        "        \n",
        "        # ------------ Train with real image ----------------\n",
        "        real = Discriminator.generate_labels(batch_size)\n",
        "        fake = Discriminator.generate_labels(batch_size, real=False)\n",
        "        \n",
        "        features = fe(x_batch)\n",
        "        discriminator_out = discriminator(features)\n",
        "        classifier_out = classifier(features)\n",
        "        \n",
        "        loss_discriminator = binary_cross_entropy(discriminator_out, real)\n",
        "        loss_classifier = binary_cross_entropy(classifier_out, y_batch)\n",
        "        \n",
        "        loss = loss_discriminator + loss_classifier\n",
        "        loss.backward()\n",
        "        discriminator.optimize(0.1)\n",
        "        classifier.optimize(0.1)\n",
        "        fe.optimize(0.1)\n",
        "        \n",
        "        losses[0] += float(loss)\n",
        "        \n",
        "        # --------------- Train with fake image -------------------\n",
        "\n",
        "        generator_input = Generator.getGeneratorInput(y_batch, batch_size)\n",
        "        \n",
        "        generated = generator(generator_input)\n",
        "        features = fe(generated)\n",
        "        discriminator_out = discriminator(features)\n",
        "        classifier_out = classifier(features)\n",
        "        \n",
        "        loss_discriminator = binary_cross_entropy(discriminator_out, fake)\n",
        "        loss_generator = binary_cross_entropy(discriminator_out, real)\n",
        "        loss_classifier = binary_cross_entropy(classifier_out, y_batch)\n",
        "        loss = loss_discriminator + loss_classifier\n",
        "        \n",
        "        loss.backward(retain_graph=True)\n",
        "        \n",
        "        discriminator.optimize(0.1)\n",
        "        fe.optimize(0.1)\n",
        "        \n",
        "        generator.zero_grad()\n",
        "        loss_generator.backward()\n",
        "        generator.optimize(0.1)\n",
        "        \n",
        "        losses[1] += float(loss_discriminator)\n",
        "        losses[2] += float(loss_classifier)\n",
        "        losses[3] += float(loss_generator)\n",
        "        \n",
        "    print(f'  Losses: {losses}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e16d4c26a37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mdiscriminator_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclassifier_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fe' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmnS51pL8Gxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    \n",
        "    index = 133\n",
        "    batch_size = 2\n",
        "    \n",
        "    x_sample = x_test[index:index+batch_size]\n",
        "    y_sample = y_test[index:index+batch_size]\n",
        "    \n",
        "    generator_input = Generator.getGeneratorInput(y_sample, batch_size)\n",
        "        \n",
        "    generated = generator(generator_input)\n",
        "    features = fe(generated)\n",
        "    discriminator_out = discriminator(features)\n",
        "    \n",
        "    features = fe(x_sample)\n",
        "    real_discriminator_out = discriminator(features)\n",
        "    classifier_out = classifier(features)\n",
        "\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "        plot_image(generated[i].reshape((28, 28)))\n",
        "        plt.show()\n",
        "        plot_image(x_sample[i].reshape((28, 28)))\n",
        "        plt.show()\n",
        "        \n",
        "    \n",
        "    print(f\"Discriminator_out fake: {discriminator_out}\\nReal Img Discriminator Out: {real_discriminator_out}\")\n",
        "    print(f\"\\nClass: {classifier_out}\\nReal class: {y_sample}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYtIu8Fp9es6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    index = 133\n",
        "    x_sample = x_test[index:index+2]\n",
        "    y_sample = y_test[index:index+2]\n",
        "    y_pred = classifier(fe(x_sample))\n",
        "    print(y_pred)\n",
        "    print(y_sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQqsDNdsbKtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}