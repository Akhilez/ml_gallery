{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "polynomial_learner.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyPbxBtub/DJGW5SxF+QwYdn",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Akhilez/ml_gallery/blob/master/ml_py/MLGallery/regressors/polynomial/polynomial_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Polynomial Equation\n",
    "\n",
    "An equation that can approximate a curve of certain complexity\n",
    "\n",
    "Curve equation => w1(x^n) + w2(x^n-1) + ... + wn(x^1) + b = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First sample: 2x^{5}+3x^{4}-2x^{3}-x^{2}+2x-1=y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = [2, 3, -2, -1, 2, -1]\n",
    "def equation (x):\n",
    "    return 2 * x**5 + 3 * x**4 -2 * x**3 -1 * x**2 + 2 * x -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = (torch.rand((100)) - 0.5) * 5\n",
    "y = equation(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PolynomialLearner (torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.order = 5\n",
    "        self.w = (torch.rand((5)) - 0.5).requires_grad_()\n",
    "        self.b = torch.zeros((1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.stack([x ** i for i in range(5, 0, -1)])\n",
    "        return sum((x.T * self.w).T) + self.b\n",
    "\n",
    "learner = PolynomialLearner()\n",
    "optimizer = torch.optim.Adam([learner.w, learner.b])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    yh = learner(x)\n",
    "\n",
    "    loss = sum((y - yh)**2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch: {epoch},\\tLoss: {loss.data.item()}')\n",
    "\n",
    "print('\\nReal\\tPredicted')\n",
    "for i in range(len(params)-1):\n",
    "    print(f'{params[i]}\\t{learner.w[i].data.item()}')\n",
    "print(f'{params[-1]}\\t{learner.b.data.item()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3ZU36Kxwkor",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-j11kqJbyMeN",
    "colab_type": "text"
   },
   "source": [
    "First sample: 2x^{5}+3x^{4}-2x^{3}-x^{2}+2x-1=y"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TEOo1bikwjkC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KbbO88iGwhC7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "params = [2, 3, -2, -1, 2, -1]\n",
    "def equation (x):\n",
    "    return 2 * x**5 + 3 * x**4 -2 * x**3 -1 * x**2 + 2 * x -1"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A2r6igHV1RVE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "x = (torch.rand((100)) - 0.5) * 5\n",
    "y = equation(x)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ehp_3hMT1kE5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class PolynomialLearner (torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.order = 5\n",
    "        self.w = (torch.rand((5)) - 0.5).requires_grad_()\n",
    "        self.b = torch.zeros((1), requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.stack([x ** i for i in range(5, 0, -1)])\n",
    "        return sum((x.T * self.w).T) + self.b\n",
    "\n",
    "learner = PolynomialLearner()\n",
    "optimizer = torch.optim.Adam([learner.w, learner.b])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DlRollAs669n",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "outputId": "3d1cb086-744b-425e-bc09-2ba347e761ab"
   },
   "source": [
    "epochs = 20000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    yh = learner(x)\n",
    "\n",
    "    loss = sum((y - yh)**2)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch: {epoch},\\tLoss: {loss.data.item()}')\n",
    "\n",
    "print('\\nReal\\tPredicted')\n",
    "for i in range(len(params)-1):\n",
    "    print(f'{params[i]}\\t{learner.w[i].data.item()}')\n",
    "print(f'{params[-1]}\\t{learner.b.data.item()}')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch: 0,\tLoss: 251928.9375\n",
      "Epoch: 1000,\tLoss: 53454.31640625\n",
      "Epoch: 2000,\tLoss: 7776.79345703125\n",
      "Epoch: 3000,\tLoss: 2069.216064453125\n",
      "Epoch: 4000,\tLoss: 1451.0550537109375\n",
      "Epoch: 5000,\tLoss: 1036.796875\n",
      "Epoch: 6000,\tLoss: 679.844482421875\n",
      "Epoch: 7000,\tLoss: 410.5437927246094\n",
      "Epoch: 8000,\tLoss: 247.730224609375\n",
      "Epoch: 9000,\tLoss: 172.2736358642578\n",
      "Epoch: 10000,\tLoss: 133.06964111328125\n",
      "Epoch: 11000,\tLoss: 96.94271087646484\n",
      "Epoch: 12000,\tLoss: 61.732120513916016\n",
      "Epoch: 13000,\tLoss: 32.67641067504883\n",
      "Epoch: 14000,\tLoss: 13.281328201293945\n",
      "Epoch: 15000,\tLoss: 3.5501787662506104\n",
      "Epoch: 16000,\tLoss: 0.4613741338253021\n",
      "Epoch: 17000,\tLoss: 0.01686829887330532\n",
      "Epoch: 18000,\tLoss: 6.901914457557723e-05\n",
      "Epoch: 19000,\tLoss: 7.744798580233692e-09\n",
      "\n",
      "Real\tPredicted\n",
      "2\t2.0\n",
      "3\t2.999999761581421\n",
      "-2\t-1.9999996423721313\n",
      "-1\t-0.9999997615814209\n",
      "2\t1.9999995231628418\n",
      "-1\t-1.0000001192092896\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "njoLI9xP7una",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}